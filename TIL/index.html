<!DOCTYPE html>
<html lang="en">

  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>TIL | Ziyue  Wang</title>
    <meta name="author" content="Ziyue  Wang">
    <meta name="description" content="Today I learnt.">
    <meta name="keywords" content="portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/monkey.png">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://ziyuewang25.github.io/TIL/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">ZiyueÂ </span>Wang</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">About</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">Blog</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">CV</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repo/">Repo</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/now/">Now</a>
              </li>
              <li class="nav-item active">
                <a class="nav-link" href="/TIL/">TIL<span class="sr-only">(current)</span></a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">TIL</h1>
            <p class="post-description">Today I learnt.</p>
          </header>

          <article>
            <h1 id="2023-08-19---2023-08-20">2023-08-19 - 2023-08-20</h1>
<ol>
  <li>Focused on <a href="https://alignmentjam.com/jam/evals" rel="external nofollow noopener" target="_blank">Eval Hackathon</a> and here is our final report  :) <a href="https://alignmentjam.com/project/can-large-language-models-solve-security-challenges" rel="external nofollow noopener" target="_blank">Can Large Language Models Solve Security Challenges?</a>.</li>
</ol>

<h1 id="2023-08-12---2023-08-18">2023-08-12 - 2023-08-18</h1>
<ol>
  <li>Read and submitted my first result to <a href="https://trojandetection.ai/start" rel="external nofollow noopener" target="_blank">trojan detection challenge</a> , <a href="https://lilianweng.github.io/posts/2021-09-25-train-large/" rel="external nofollow noopener" target="_blank">How to Train Really Large Models on Many GPUs?</a>,</li>
  <li>Wrote a blog post about <a href="https://ziyuewang25.github.io/blog/2023/DLC-T9-AdversarialTraining/">Red Teaming Language Models with Language Models</a>
</li>
  <li>Did my first introductory to EA course.</li>
  <li>Read many paper/blogs/code about Adversarial Training &amp; Safety Evaluation for <a href="https://alignmentjam.com/jam/evals" rel="external nofollow noopener" target="_blank">Eval Hackathon</a> , I am currently working on this.</li>
</ol>

<h1 id="2023-08-01---2023-08-11">2023-08-01 - 2023-08-11</h1>
<ol>
  <li>Finished DLC Alignment topic exericise, it takes me around 30 hours. The code is here: <a href="https://github.com/ZiyueWang25/RLHF-Shakespeare" rel="external nofollow noopener" target="_blank">Finetune LLM with RLHF to generate positive tone message from Shakespeare Corpus</a>
</li>
  <li>Finished <a href="https://course.aisafetyfundamentals.com/alignment?week=3" rel="external nofollow noopener" target="_blank">Week 3 Goal Misgeneralization</a> and <a href="https://course.aisafetyfundamentals.com/home/alignment?week=4" rel="external nofollow noopener" target="_blank">Week 4 Task Decomposition for scalable oversight</a> reading</li>
  <li>Wrote blog posts <a href="https://ziyuewang25.github.io/blog/2023/DLC-T1-MI/">Find the induction heads in GPT-2</a> and <a href="https://ziyuewang25.github.io/blog/2023/ARENA/">ARENA learning experience</a>
</li>
</ol>

<h1 id="2023-07-24---2023-07-31">2023-07-24 - 2023-07-31</h1>
<ol>
  <li>In the progress of doing Alignment exercise in <a href="https://github.com/jacobhilton/deep_learning_curriculum/tree/master" rel="external nofollow noopener" target="_blank">DLC</a>
</li>
  <li>Finished <a href="https://course.aisafetyfundamentals.com/alignment?week=2" rel="external nofollow noopener" target="_blank">Week 2 Reward Misspecification</a> reading</li>
  <li>Read <a href="https://forum.effectivealtruism.org/s/B79ro5zkhndbBKRRX" rel="external nofollow noopener" target="_blank">the effectiveness mindset</a> chapter for the <a href="https://www.effectivealtruism.org/virtual-programs/introductory-program" rel="external nofollow noopener" target="_blank">introductory to EA</a> course.</li>
  <li>travel week (Beijing, Shanghai, Hangzhou). Met many friends and had great fun!</li>
</ol>

<h1 id="2023-07-16---2023-07-23">2023-07-16 - 2023-07-23</h1>
<ol>
  <li>Around 15 hours to finish <a href="https://colab.research.google.com/drive/1xTpfj6xADQYdUudnZE9AWMUzyr8DBoU6?usp=sharing" rel="external nofollow noopener" target="_blank">Topic 2 Scaling Laws</a> in <a href="https://github.com/jacobhilton/deep_learning_curriculum/tree/master" rel="external nofollow noopener" target="_blank">DLC</a>.  I wrote a post about it <a href="https://ziyuewang25.github.io/blog/2023/DLC-T2-Scaling-Laws/">here</a>
</li>
  <li>Around 7 hours to finish <a href="https://arena-ch2-rl.streamlit.app/" rel="external nofollow noopener" target="_blank">week2_deep_Q_Learning</a>.</li>
  <li>Around 4 hours to finish <a href="https://colab.research.google.com/drive/1UlhPmIfhQLo_10r5OkDwLxWF--A2iCKc?usp=sharing" rel="external nofollow noopener" target="_blank">week2_PPO</a>. The Atari Breakout game result is shown <a href="https://wandb.ai//vincentwang25/PPOAtari/reports/videos-23-07-18-13-10-22---Vmlldzo0OTA1MjM0" rel="external nofollow noopener" target="_blank">here</a>.</li>
  <li>Around 25 hours to finish Topic 6 Reinforcement Learning in DLC. The solution is written in colab <a href="https://colab.research.google.com/drive/1n8EhT0RHxdS1MIgiPQkvjDX7sD7Mpxoy?usp=sharing" rel="external nofollow noopener" target="_blank">here</a>. The post is written <a href="https://ziyuewang25.github.io/blog/2023/DLC-T6-RL/">here</a>
</li>
</ol>

<h1 id="2023-07-01---2023-07-15">2023-07-01 - 2023-07-15</h1>
<p>Flight back to China. Time with family and friends.</p>

<h1 id="2023-06-25---2023-06-30">2023-06-25 - 2023-06-30</h1>
<ol>
  <li>Around 2 hours to finish exercise <a href="https://colab.research.google.com/drive/1HjzmCYqBVz_Q0XVj0mmOZGV26tW1WvHi?usp=sharing" rel="external nofollow noopener" target="_blank">week0_d4_optimization</a>. Learnt about details of various optimizer, <code class="language-plaintext highlighter-rouge">Weight &amp; Bias</code> related usage.</li>
  <li>Around 2 hours to finish exercise <a href="https://colab.research.google.com/drive/1WjtXIlpr3iC5fPGC4_hGSm6nYMdIptNc?usp=sharing" rel="external nofollow noopener" target="_blank">week0_d5_backprop</a>. Learnt about details of back propagation &amp; Autograd. Skipped part 3 &amp; 4 &amp; 5.</li>
  <li>Around 3 hours to finish exercise <a href="https://colab.research.google.com/drive/1Ig779Od-OoO8lHolRqWQTaAvhK98EdJT?usp=sharing" rel="external nofollow noopener" target="_blank">week1_d1_transformer</a>. Learnt about details of transformer, sampling, training and inference sampling. Skipped part of sampling.</li>
  <li>Around 5 hours to finish exercise <a href="https://colab.research.google.com/drive/1NfLlt3McxOK9eY4xT_S6Q0ZFaoXtrW2B?usp=sharing" rel="external nofollow noopener" target="_blank">week1_d2_mechanistic_interpretability</a>. Learnt about induction circuits, transformerLens, induction heads, hooks, reverse-engineering induction circuits. These material opened a new view for me about how to understand LLM. I find some part hard to understand though and skipped some of the exercise as I donât want to spend too much time on this topic for now.</li>
  <li>Around 3 hours to finish <a href="https://colab.research.google.com/drive/15CSZ09T0LQ4_BAM7_NcGDy5sTVneFJQw?usp=sharing" rel="external nofollow noopener" target="_blank">Topic 8 Interpretability</a> in <a href="https://github.com/jacobhilton/deep_learning_curriculum/blob/master/8-Interpretability.md" rel="external nofollow noopener" target="_blank">DLC</a>. It didnât take me too long because ARENA courses covered most of it.</li>
  <li>Around 2.5 hours to finish <a href="https://arena-ch2-rl.streamlit.app/" rel="external nofollow noopener" target="_blank">week2_d1_intro_to_RL</a>, it works like a memory refresher about some RL concepts. It is nice to check the detail of some RL environments.</li>
</ol>

<h1 id="2023-06-20---2023-06-24">2023-06-20 - 2023-06-24</h1>
<ol>
  <li>Around 2.3 hours to finish exercise <a href="https://colab.research.google.com/drive/1tmwlA1YQIrgXblzo_9q2mNvEOuAqsV3N?usp=sharing" rel="external nofollow noopener" target="_blank">week0_d2_cnn</a>. Learnt about <code class="language-plaintext highlighter-rouge">torch.as_strided</code> related stuff.</li>
  <li>Around 2.4 hours to finish exercise <a href="https://colab.research.google.com/drive/1gnUiIAzIvjYvaUXdZP7J8e_n1qeLhHFj?usp=sharing" rel="external nofollow noopener" target="_blank">week0_d3_resnet</a>. Learnt a more detailed view about resnet, pytorch_lighting, batchnorm</li>
  <li>induction head <a href="https://www.lesswrong.com/posts/TvrfY4c9eaGLeyDkE/induction-heads-illustrated" rel="external nofollow noopener" target="_blank">understanding</a>
</li>
  <li><a href="https://docs.google.com/document/d/1WwsnJQstPq91_Yh-Ch2XRL8H_EpsnjrC1dwZXR37PC8/edit#heading=h.kkaua0hwmp1d" rel="external nofollow noopener" target="_blank">Eliciting latent knowledge</a></li>
</ol>

<h1 id="2023-06-14---2023-06-19">2023-06-14 - 2023-06-19</h1>
<ol>
  <li>Followed <a href="https://github.com/jacobhilton/deep_learning_curriculum" rel="external nofollow noopener" target="_blank">Deep Learning Curriculum</a> and finished <a href="https://github.com/jacobhilton/deep_learning_curriculum/blob/master/1-Transformers.md" rel="external nofollow noopener" target="_blank">Topic 1 Transformer</a>, it takes me about 20 hours but I learnt a lot throughout the process. I wrote a post about it <a href="https://ziyuewang25.github.io/blog/2023/DLC-T1-Transformer/">here</a>
</li>
  <li>Read Mechanistic Interpretability related materials: <a href="https://www.neelnanda.io/mechanistic-interpretability/getting-started" rel="external nofollow noopener" target="_blank">Concrete Steps to Get Started in Transformer Mechanistic Interpretability</a> and Google Internal documents about Introduction to Alignment.</li>
</ol>

<h1 id="2023-06-08---2023-06-13">2023-06-08 - 2023-06-13</h1>
<ol>
  <li>DDPM and DDIM diffusion Pytorch version replication: <a href="https://colab.research.google.com/drive/1LcxLcVfxeFQWlEEWVTBx_LfNMaY3CoNg?usp=sharing" rel="external nofollow noopener" target="_blank">DiffusionModel-DeepLearningAI-Pytorch.ipynb</a> . It takes me a while to collect the data to mimic the short <a href="https://www.deeplearning.ai/short-courses/how-diffusion-models-work/" rel="external nofollow noopener" target="_blank">course</a> on DeepLearning.AI and in the end I decide to use MNIST data with customized label to replicate the results.  The script works well and I am glad to see the model can generate digits according to the given conditions.</li>
  <li>Kaggle LLM Nerd-Off. Checked out the existing model performance and competition data details. Since the model size constraint is 1B, it seems to me that specialized model to deal with different kind of input is the way to go. Also, parameter-efficient fine-tuning methods are definitely important.</li>
  <li>Some more readings about AI Safety in <a href="https://aisafetyfundamentals.com/ai-alignment-curriculum" rel="external nofollow noopener" target="_blank">week 1</a>. It is fun to see the <a href="https://www.deepmind.com/blog/specification-gaming-the-flip-side-of-ai-ingenuity" rel="external nofollow noopener" target="_blank">Specification Gaming</a> issue.</li>
  <li>
<a href="https://utilitarianism.net/peter-singer-famine-affluence-and-morality/" rel="external nofollow noopener" target="_blank">Famine, Affluence, and Morality</a>: it motivates me to donate 10% of my income to do more goods effectively.</li>
  <li>Consultation with 80k hours works well. I am glad I did it :)</li>
</ol>

<h1 id="2023-06-07">2023-06-07</h1>
<ol>
  <li>Reviewed previous experience about <a href="https://arxiv.org/abs/1808.03668" rel="external nofollow noopener" target="_blank">DeepLOB</a> and <a href="https://github.com/ZiyueWang25/Kaggle_G2Net" rel="external nofollow noopener" target="_blank">Kaggle Gravitation Wave Detection Competition</a>. Feels like it has been quite a while. I miss the feeling of doing DL models.</li>
  <li>Reviewed <a href="https://www.deeplearning.ai/short-courses/how-diffusion-models-work/" rel="external nofollow noopener" target="_blank">How Diffusion Models Work</a> short course again on DeepLearning.AI. I will work on replicating it in Pytorch/JAX. It looks fun!</li>
</ol>

<h1 id="2023-06-01---2023-06-06">2023-06-01 - 2023-06-06</h1>
<ol>
  <li>AI Safety related topics:
    <ol>
      <li>
<a href="https://aisafetyfundamentals.com/ai-alignment-curriculum" rel="external nofollow noopener" target="_blank">Alignment Course - AI Safety Fundamentals</a>: week 0 + week1</li>
      <li><a href="https://drive.google.com/file/d/1uK7NhdSKprQKZnRjU58X7NLA1auXlWHt/view" rel="external nofollow noopener" target="_blank">AGI safety from first principles</a></li>
      <li>Various AI Safety team from different companies: Google DeepMind, OpenAI, Anthropic, etc.</li>
      <li><a href="https://80000hours.org/problem-profiles/artificial-intelligence/?source=email&amp;uni_id=867&amp;utm_source=80%2C000+Hours+mailing+list&amp;utm_campaign=332544752a-EMAIL_CAMPAIGN_2023_06_01_11_29&amp;utm_medium=email&amp;utm_term=0_43bc1ae55c-71ae16e3db-%5BLIST_EMAIL_ID%5D" rel="external nofollow noopener" target="_blank">Preventing an AI-related catastrophe</a></li>
      <li><a href="https://intelligence.org/2015/07/24/four-background-claims/" rel="external nofollow noopener" target="_blank">Four Background Claims</a></li>
      <li><a href="https://medium.com/@richardcngo/visualizing-the-deep-learning-revolution-722098eb9c5" rel="external nofollow noopener" target="_blank">Visualizing the deep learning revolution</a></li>
    </ol>
  </li>
  <li>Google internal Kaggle competition: LLM Nerd-off. First submission :)</li>
  <li>Deep Learning AI 4 Short <a href="https://www.deeplearning.ai/short-courses/" rel="external nofollow noopener" target="_blank">courses</a>
</li>
  <li>1 on 1 consultation <a href="https://80000hours.org/speak-with-us/?int_campaign=homepage__get-1-1-advice" rel="external nofollow noopener" target="_blank">chat</a> with 80k hours.</li>
  <li>Finish reading <a href="https://www.goodreads.com/book/show/23398748-doing-good-better" rel="external nofollow noopener" target="_blank">Doing Good Better: How Effective Altruism Can Help You Make a Difference</a>
</li>
  <li>Reading <a href="https://www.goodreads.com/book/show/50489349-the-alignment-problem" rel="external nofollow noopener" target="_blank">The alignment problem</a>
</li>
</ol>

<h1 id="2023-05-25">2023-05-25</h1>
<ol>
  <li>
<a href="https://80000hours.org/podcast/episodes/olsson-and-ziegler-ml-engineering-and-safety/" rel="external nofollow noopener" target="_blank">podcast: PhD or programming?Fast paths into aligning AI as a machine learning engineer, according to ML engineers Catherine Olsson &amp; DanielÂ Ziegler</a>: dive in, write detail plan and ask mentor to guide</li>
  <li>
<a href="https://mindingourway.com/dive-in-2/" rel="external nofollow noopener" target="_blank">Dive In</a>:
    <ol>
      <li>
<a href="https://mindingourway.com/conviction-without-s/" rel="external nofollow noopener" target="_blank">conviction without self-deception</a>: stop conflating feelings with beliefs.</li>
      <li>
<a href="https://mindingourway.com/deliberate-once/" rel="external nofollow noopener" target="_blank">deliberate once</a>: about making big decision, deliberate once and then donât deliberate again until new information comes in that would have changed the result of the deliberation.
        <ol>
          <li>commitment-aversion thoughts</li>
          <li>abort notice</li>
          <li>confusion pings</li>
        </ol>
      </li>
      <li>realize that you find good things to do by getting your hands dirty</li>
    </ol>
  </li>
</ol>

<h1 id="2023-05-20---2023-05-23">2023-05-20 - 2023-05-23</h1>
<ol>
  <li>Virtual Try-on models:
    <ol>
      <li>
<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_TryOnDiffusion_A_Tale_of_Two_UNets_CVPR_2023_paper.pdf" rel="external nofollow noopener" target="_blank">TryOnDiffusion: A Tale of Two UNets</a>: parallel-UNet, cross-attention, cascade diffusion, FiLM, Efficient UNet. Amazing results!</li>
      <li>
<a href="https://arxiv.org/abs/2206.14180" rel="external nofollow noopener" target="_blank">High-Resolution Virtual Try-On with Misalignment and Occlusion-Handled Conditions</a>: classic Virtual Try On (VITON) model by warping the cloth first and then blend with the target person.</li>
      <li><a href="https://tryongan.github.io/tryongan/" rel="external nofollow noopener" target="_blank">TryOnGAN</a></li>
      <li><a href="https://arxiv.org/abs/2207.09161" rel="external nofollow noopener" target="_blank">Single Stage Virtual Try-on via Deformable Attention Flows</a></li>
    </ol>
  </li>
  <li>
<a href="https://distill.pub/2018/feature-wise-transformations/" rel="external nofollow noopener" target="_blank">FiLM</a>: a way to combine concatenation &amp; multiplication feature transformation.</li>
  <li>Diffusion Model Related read:
    <ol>
      <li>
<a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/" rel="external nofollow noopener" target="_blank">What are Diffusion Models?</a> by Lilian Weng</li>
      <li>
<a href="https://huggingface.co/blog/annotated-diffusion" rel="external nofollow noopener" target="_blank">The Annotated Diffusion Model</a> by huggingface</li>
      <li><a href="https://arxiv.org/abs/2209.00796" rel="external nofollow noopener" target="_blank">Diffusion Models: A Comprehensive Survey of Methods and Applications</a></li>
      <li>
<a href="https://arxiv.org/abs/2006.11239" rel="external nofollow noopener" target="_blank">Denoising Diffusion Probabilistic Models</a>: classic DDPM algorithm</li>
      <li>
<a href="https://arxiv.org/abs/2102.09672" rel="external nofollow noopener" target="_blank">Improved Denoising Diffusion Probabilistic Models</a>: learning variance of the reverse diffusion process.</li>
      <li>
<a href="https://arxiv.org/abs/2010.02502" rel="external nofollow noopener" target="_blank">Denoising Diffusion Implicit Models</a>: DDIM , a more efficient iterative process for the reverse diffusion part.</li>
      <li>
<a href="https://arxiv.org/abs/2105.05233" rel="external nofollow noopener" target="_blank">Diffusion Models Beat GANs on Image Synthesis</a>: classifier guidance</li>
      <li>
<a href="https://arxiv.org/abs/2104.07636" rel="external nofollow noopener" target="_blank">Classifier-Free Diffusion Guidance</a>: classifier-free guidance</li>
      <li>
<a href="https://ieeexplore.ieee.org/document/9878449" rel="external nofollow noopener" target="_blank">High-Resolution Image Synthesis with Latent Diffusion Models</a>: cross attention.</li>
      <li><a href="https://arxiv.org/abs/2104.07636" rel="external nofollow noopener" target="_blank">Image Super-Resolution via Iterative Refinement</a></li>
      <li><a href="https://arxiv.org/abs/2106.15282" rel="external nofollow noopener" target="_blank">Cascaded Diffusion Models for High Fidelity Image Generation</a></li>
      <li>
<a href="https://arxiv.org/abs/2111.05826" rel="external nofollow noopener" target="_blank">Palette: Image-to-Image Diffusion Models</a>: image to image diffusion model</li>
      <li>
<a href="https://arxiv.org/abs/2205.11487" rel="external nofollow noopener" target="_blank">Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding</a>: text-to-image model by leveraging LLM.</li>
    </ol>
  </li>
  <li>Human pose and segmentation:
    <ol>
      <li><a href="https://arxiv.org/abs/1701.01779" rel="external nofollow noopener" target="_blank">Towards Accurate Multi-person Pose Estimation in the Wild</a></li>
      <li><a href="https://arxiv.org/abs/1904.04536" rel="external nofollow noopener" target="_blank">Graphonomy: Universal Human Parsing via Graph Transfer Learning</a></li>
    </ol>
  </li>
  <li>
<a href="https://sites.research.google/parti/" rel="external nofollow noopener" target="_blank">Parti</a>: Pathways Autoregressive Text-to-Image model</li>
</ol>

<h1 id="2023-05-17---2023-05-19">2023-05-17 - 2023-05-19</h1>
<ol>
  <li>Replicating <a href="https://arxiv.org/abs/1706.03762" rel="external nofollow noopener" target="_blank">Attention is all you need</a> paper in JAX/Flax/Optax.</li>
</ol>

<h1 id="2023-05-16">2023-05-16</h1>
<ol>
  <li>
<a href="https://forum.effectivealtruism.org/posts/7WXPkpqKGKewAymJf/how-to-pursue-a-career-in-technical-ai-alignment" rel="external nofollow noopener" target="_blank">How to pursue a career in technical AI alignment</a>: this is amazing post about ML/DL/AI alignment.</li>
</ol>

<h1 id="2023-05-15">2023-05-15</h1>
<ol>
  <li>
<a href="https://hubermanlab.com/leverage-dopamine-to-overcome-procrastination-and-optimize-effort/" rel="external nofollow noopener" target="_blank">Leverage Dopamine to Overcome Procrastination &amp; Optimize Effort</a>: this podcast episode is interesting and informative. The biggest takeaway for me is to understand how our motivation level changes according to dopamine and what the dopamine circuit is like. It is also surprising to learn that we can leverage something that sucks to overcome procrastination. A good summary can be found <a href="https://podcastnotes.org/huberman-lab/leverage-dopamine-to-overcome-procrastination-optimize-effort-huberman-lab/" rel="external nofollow noopener" target="_blank">here</a>
</li>
  <li>Instead of reading paper, I should spend more time getting my hands dirty. It is harder and has more direct impact on my career.</li>
</ol>

<h1 id="2023-05-14">2023-05-14</h1>
<ol>
  <li>
<a href="https://www.matthewtancik.com/nerf" rel="external nofollow noopener" target="_blank">NeRF - Representing Scenes as Neural Radiance Fields for View Synthesis</a>: First time tackling 3D image synthesis problem. Followed <a href="https://github.com/bmild/nerf/blob/master/tiny_nerf.ipynb" rel="external nofollow noopener" target="_blank">tiny_nerf.ipynb</a> notebook and added hierarchical sampling on it. <a href="https://colab.research.google.com/drive/1U18TrmcnL1TpZj1R-qv43hsxfu_DizOc?usp=sharing" rel="external nofollow noopener" target="_blank">tiny_nerf_with_hierarchical_sampling.ipynb</a>
</li>
  <li>
<a href="https://nerf-w.github.io/" rel="external nofollow noopener" target="_blank">NeRF in the Wild</a>: add a series of extensions to NeRF to address dynamic subjects captured under uncontrolled setting.</li>
</ol>

<h1 id="2023-05-13">2023-05-13</h1>
<ol>
  <li>
<a href="https://blog.google/technology/research/project-starline/" rel="external nofollow noopener" target="_blank">Project Starline</a>: 3D display to connect people. <a href="https://www.youtube.com/watch?v=kDgToq5aXh0&amp;ab_channel=GoogleAR%26VR" rel="external nofollow noopener" target="_blank">video</a>
</li>
  <li>
<a href="https://3d-diffusion.github.io/" rel="external nofollow noopener" target="_blank">Novel View Synthesis with Diffusion Models</a>: 3D generation from a few image pairs.</li>
  <li>
<a href="https://bmild.github.io/rawnerf/" rel="external nofollow noopener" target="_blank">NeRF in the Dark: High Dynamic Range View Synthesis from Noisy Raw Images</a>:</li>
  <li>
<a href="https://time-travel-rephotography.github.io/" rel="external nofollow noopener" target="_blank">Time-Travel Rephotography</a>: use styleGAM2 framework to project old photo into modern high-resolution photos</li>
  <li><a href="https://hypernerf.github.io/" rel="external nofollow noopener" target="_blank">HyperNeRF: A Higher-Dimensional Representation for Topologically Varying Neural Radiance Fields</a></li>
</ol>

<h1 id="2023-05-12">2023-05-12</h1>
<ol>
  <li>
<a href="https://openai.com/research/whisper" rel="external nofollow noopener" target="_blank">Whisper</a>: English speech recognition</li>
  <li>
<a href="https://www.deepspeed.ai/tutorials/zero/" rel="external nofollow noopener" target="_blank">Zero Redundancy Optimizer</a> :partitioning various model training states across the available devices</li>
  <li><a href="https://bigscience.huggingface.co/blog/bloom" rel="external nofollow noopener" target="_blank">BLOOM: A 176B-Parameter Open-Access Multilingual Language Model</a></li>
  <li>I got a personal poem written by Melanie Reed when we walk around Green Lake. It is beautiful and touching.</li>
</ol>

<h1 id="2023-05-11">2023-05-11</h1>
<ol>
  <li>
<a href="https://80000hours.org/" rel="external nofollow noopener" target="_blank">80,000 hours</a>: 80,000 hours in yourÂ career. The <a href="https://80000hours.org/key-ideas/" rel="external nofollow noopener" target="_blank">key ideas</a> page is amazing.</li>
  <li><a href="https://blog.google/technology/ai/google-palm-2-ai-large-language-model/" rel="external nofollow noopener" target="_blank">PaLM2</a></li>
  <li>
<a href="https://ai.googleblog.com/2022/10/ul2-20b-open-source-unified-language.html" rel="external nofollow noopener" target="_blank">UL2</a>: A way to include encoder like and decoder like training objective together.</li>
  <li>Some exploration about green card application @ Australia, Germany, Netherlands and Sweden. Be mentally prepared for the Chinese discrimination in the USA.</li>
</ol>

<h1 id="2023-05-10">2023-05-10</h1>
<ol>
  <li>
<a href="https://jingfengyang.github.io/gpt" rel="external nofollow noopener" target="_blank">Why did all of the public reproduction of GPT-3 fail? In which tasks should we use GPT-3.5/ChatGPT?</a>: A practical point of view to compare different LLM reproduction and application issue.</li>
  <li>
<a href="https://imagebind.metademolab.com/" rel="external nofollow noopener" target="_blank">ImageBind</a>: wow, the idea is pretty straightforward: learning the joint embedding from multiple modalities. Using image as the central embedding. Interesting!</li>
</ol>

<h1 id="2023-05-09">2023-05-09</h1>
<ol>
  <li>
<a href="https://github.com/Mooler0410/LLMsPracticalGuide" rel="external nofollow noopener" target="_blank">Harnessing the power of LLMs in Practice</a>: the chart inside is quite informative and the future trend is also thoughtful: evaluation on real-world datasets, alignment, safety.</li>
  <li>To do great things, focus on small stuff.</li>
  <li>To make a fortune, help 1-billion people or make a grand breakthrough.</li>
</ol>

<h1 id="2023-05-08">2023-05-08</h1>
<ol>
  <li>
<a href="https://nownownow.com/" rel="external nofollow noopener" target="_blank">Now Page</a>: A simple but quite informative and fun page created by Derek Sivers.</li>
  <li>
<a href="https://www.datacomp.ai/" rel="external nofollow noopener" target="_blank">DataComp</a>: A framework about improving dataset by fixing model.
    <ol>
      <li>
<a href="https://github.com/unitaryai/detoxify" rel="external nofollow noopener" target="_blank">Detoxify</a>: model to remove unsafe content.</li>
      <li>Deduplication using constrastive learning. <a href="https://arxiv.org/pdf/2112.04323.pdf" rel="external nofollow noopener" target="_blank">link</a>
</li>
      <li>Face detection and blurring for privacy. <a href="https://arxiv.org/abs/2105.04714" rel="external nofollow noopener" target="_blank">detection model</a>. <a href="https://arxiv.org/abs/2103.06191" rel="external nofollow noopener" target="_blank">blurring effect</a>
</li>
    </ol>
  </li>
  <li>We definitely need to advocate for ourselves.</li>
  <li>Cleaning up the system can be time-consuming and a headache.</li>
</ol>


          </article>

        </div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        Â© Copyright 2023 Ziyue  Wang. 
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-GF7DRR9GYB"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-GF7DRR9GYB');
  </script>
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
