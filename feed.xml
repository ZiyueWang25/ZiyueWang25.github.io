<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://ziyuewang25.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://ziyuewang25.github.io/" rel="alternate" type="text/html" hreflang="en" /><updated>2023-08-01T00:00:43+00:00</updated><id>https://ziyuewang25.github.io/feed.xml</id><title type="html">blank</title><subtitle>Think -&gt; Experiment -&gt; Create -&gt; Serve :)
</subtitle><entry><title type="html">How to get gold medal in Kaggle competition, from a Competition Master perspective.</title><link href="https://ziyuewang25.github.io/blog/2023/win-thoughts/" rel="alternate" type="text/html" title="How to get gold medal in Kaggle competition, from a Competition Master perspective." /><published>2023-07-29T00:00:00+00:00</published><updated>2023-07-29T00:00:00+00:00</updated><id>https://ziyuewang25.github.io/blog/2023/win-thoughts</id><content type="html" xml:base="https://ziyuewang25.github.io/blog/2023/win-thoughts/"><![CDATA[<p>I started doing Kaggle competition seriously since 2021 February and became Kaggle Competition Master on 2022 March. During that 1 year, I have won 2 gold, 1 silver and 2 bronze medals.</p>

<p><img src="https://i.ibb.co/MBHJMmG/2023-07-29-15-40.png" alt="" /></p>

<p>Here is my 7 suggestions about how to win a Competition:</p>

<ol>
  <li>
    <p>Hard work: the competition I participated in usually takes me around 200 hours to get a decent result (Silver¬†+). Definitely, the time¬†needed can be lower with more experience.</p>
  </li>
  <li>
    <p>Teamwork: teaming up with experienced people can boost the learning process and also get a higher chance to win</p>
  </li>
  <li>
    <p>Jump out of local optimum: don‚Äôt spend too much time on hyperparameter tuning or small model structure tuning but rather put more data on data investigation, feature engineering, and very different model structure.</p>
  </li>
  <li>
    <p>Good pipeline: preprocess -&gt; model training -&gt; post-process, machine learning pipeline can be complex but having a good pipeline is essential because it allows more experiments and thus gives a higher chance to hit the lucky spot.</p>
  </li>
  <li>
    <p>Good Cross-Validation setting: Having a good CV setting can be great to find the right direction to go fast. Relying on Public LB can be sometimes quite dangerous and slow.</p>
  </li>
  <li>
    <p>Curiosity: Having enough interest in the competition is probably the main driven motivation for me to push higher and higher scores.</p>
  </li>
  <li>
    <p>Learning one topic at a time: don‚Äôt get overwhelmed by too much information at one time, just take one discussion post or one kernel to learn. We will catch up in the end with enough time. Playing Kaggle is not like horse racing but rather a research process.</p>
  </li>
</ol>

<p>Hope this can be helpful to some extent. Let me know if there is anything else you are interested!</p>]]></content><author><name></name></author><category term="AI" /><category term="ML" /><summary type="html"><![CDATA[I summarized 7 key points about how to get a Kaggle competition gold medal.]]></summary></entry><entry><title type="html">Implementing PPO from scratch</title><link href="https://ziyuewang25.github.io/blog/2023/DLC-T6-RL/" rel="alternate" type="text/html" title="Implementing PPO from scratch" /><published>2023-07-23T00:00:00+00:00</published><updated>2023-07-23T00:00:00+00:00</updated><id>https://ziyuewang25.github.io/blog/2023/DLC-T6-RL</id><content type="html" xml:base="https://ziyuewang25.github.io/blog/2023/DLC-T6-RL/"><![CDATA[<p>I started following <a href="https://github.com/jacobhilton/deep_learning_curriculum/tree/master">Deep Learning Curriculum</a>(DLC) written by <a href="https://www.jacobh.co.uk/">Jacob Hilton</a> and here is what I experienced and learnt from the exercise in <a href="https://github.com/jacobhilton/deep_learning_curriculum/blob/master/6-Reinforcement-Learning.md">Topic 6 - Reinforcement Learning</a>. My solution is written in Colab <a href="https://colab.research.google.com/drive/1n8EhT0RHxdS1MIgiPQkvjDX7sD7Mpxoy?usp=sharing">T6-RL-solution.ipynb</a></p>

<p>It took me around 40 hours to finish the exercise. I started by spending around 15 hours doing the exercise in <a href="https://github.com/callummcdougall/ARENA_2.0/tree/main">ARENA</a> about RL to get myself familiar with different components in RL and then spending the rest 25 hours doing the DLC exercise.</p>

<p>I referred to the ARENA‚Äôs exercise solution heavily since I have done them. To implement and debug the RL algorithm, I referred to posts <a href="https://andyljones.com/posts/rl-debugging.html">Debugging RL, Without the Agonizing Pain</a> and <a href="https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/">The 37 Implementation Details of Proximal Policy Optimization</a>.</p>

<p>I used Colab Pro+ environment to enable background running and more compute. The experimentation is done using 1 V100 GPU.</p>

<p>I have generated the  Result <a href="https://wandb.ai/vincentwang25/PPOProcgen/reports/PPO-Implementation-in-Procgen-Env--Vmlldzo0OTQ3NzE5?accessToken=s9w0lpjb2fjv77ouf1c7nrb2s0zcviymc0mmw8pksr34mnsiblw5x7t7izv5gbhs">Report</a> in Weights &amp; Bias. It shows</p>

<ol>
  <li>Increasing amount of episode return</li>
  <li>reasonable amount of ratios clipped by PPO.</li>
  <li>Small and fairly stable approximate KL.</li>
  <li>Policy entropy (relative entropy) falls gradually</li>
  <li>Value residual Variance (1 - value explained variance) tend to something positive.</li>
  <li>Mean and standard deviation for advantage normalization are fairly stable and mean is pretty close to zero.</li>
</ol>

<p><img src="https://i.ibb.co/9rkgjbc/2023-07-23-09-12.png" alt="" /></p>

<p><img src="https://i.ibb.co/nQzcTBs/2023-07-23-09-13.png" alt="" /></p>

<p>Another closer look at the episode return. It shows that using IMPALA model performs better than traditional CNN, especially at <code class="language-plaintext highlighter-rouge">bigfish</code> environment.</p>

<p><img src="https://i.ibb.co/2g1Pjfd/2023-07-23-09-16.png" alt="" /></p>

<p>Other than these results, I found implementing the PPO algorithm under customized easy probing environments quite helpful. It is also helpful to achieve decent performance under CartPole environment and Atari environments before moving into harder Procgen Environments.</p>

<p>Extensively track the metrics can also be helpful to debug where things went wrong or well, though relying on some of them solely might be inadequate. I am confused by <a href="https://andyljones.com/posts/rl-debugging.html#:~:text=handling%20invalid%20actions.-,Residual%20variance,-The%20variance%20of">residual variance</a> oscillation inside CartPole environment before, i.e. the residual variance doesn‚Äôt go smoothly towards a positive value, but <a href="https://wandb.ai//vincentwang25/PPOCart/reports/PPO-CartPPO-CartPole-Wrong-Value-Residual-Variance--Vmlldzo0OTE1NTcw?accessToken=jb0t273joya2ec1a4xaiefydzhb5qd0h1wekl40yo55cr9r6mcz6t25ibj0otim4">oscillate wildly</a>. It turns out that this can be due to the inherent simplicity of the CartPole environment: it doesn‚Äôt need much value estimation, but more relying on planning. This cause the value estimation to be unstable.</p>

<p>Overall I found this exercise quite helpful for me to understand the PPO algorithm and generally RL algorithm structure.</p>]]></content><author><name></name></author><category term="AI" /><category term="ML" /><summary type="html"><![CDATA[I tried to implementing PPO from scratch and apply it to Procgen environment. Here is what I learnt.]]></summary></entry><entry><title type="html">Replicating Scaling Laws by using MNIST data</title><link href="https://ziyuewang25.github.io/blog/2023/DLC-T2-Scaling-Laws/" rel="alternate" type="text/html" title="Replicating Scaling Laws by using MNIST data" /><published>2023-07-10T00:00:00+00:00</published><updated>2023-07-10T00:00:00+00:00</updated><id>https://ziyuewang25.github.io/blog/2023/DLC-T2-Scaling%20Laws</id><content type="html" xml:base="https://ziyuewang25.github.io/blog/2023/DLC-T2-Scaling-Laws/"><![CDATA[<p>I started following <a href="https://github.com/jacobhilton/deep_learning_curriculum/tree/master">Deep Learning Curriculum</a> written by <a href="https://www.jacobh.co.uk/">Jacob Hilton</a> and here is what I learnt from the exercise in <a href="https://github.com/jacobhilton/deep_learning_curriculum/blob/master/2-Scaling-Laws.md">Topic 2 - Scaling Laws</a>. My solution is written in Colab <a href="https://colab.research.google.com/drive/1xTpfj6xADQYdUudnZE9AWMUzyr8DBoU6?usp=sharing">T2-ScalingLaws-solution.ipynb</a></p>

<p>It took me around 15 hours to finish the exercise. Throughout the process I learnt:</p>
<ol>
  <li>How to vary the CNN width and training data to follow scaling laws experimentation set up.</li>
  <li>How to use Pytorch lighting learning rate finder to adjust the learning rate based on model size.
    <ol>
      <li>use <code class="language-plaintext highlighter-rouge">callbacks.LearningRateFinder</code> from pytorch lighting and do some experimentation to find the proper minimum and maximum learning rate to search from. Plot the learning rate to make sure the result looks right. <img src="https://i.ibb.co/BBN4gyc/lr-plot.png" alt="" /></li>
    </ol>
  </li>
  <li>How the compute-efficient model size varies with compute.
    <ol>
      <li>To approximate the relationship between compute and loss, we can use <a href="https://www.cuemath.com/calculus/cube-root-function/">Cubic Root Function</a>. We need to train more episodes to enable an accurate approximation.</li>
    </ol>
  </li>
</ol>

<p><img src="https://i.ibb.co/41vg6jL/download-2.png" alt="" /></p>

<p><img src="https://i.ibb.co/zNDhTpD/download.png" alt="" />
<img src="https://i.ibb.co/dgSp0MN/download-1.png" alt="" /></p>]]></content><author><name></name></author><category term="AI" /><category term="ML" /><summary type="html"><![CDATA[I tried to replicating scaling laws result by using MNIST data. Here is what I learnt.]]></summary></entry><entry><title type="html">Replicating Decoder-only Transformer by using William Shakespeare Corpus</title><link href="https://ziyuewang25.github.io/blog/2023/DLC-T1-Transformer/" rel="alternate" type="text/html" title="Replicating Decoder-only Transformer by using William Shakespeare Corpus" /><published>2023-06-19T00:00:00+00:00</published><updated>2023-06-19T00:00:00+00:00</updated><id>https://ziyuewang25.github.io/blog/2023/DLC-T1-Transformer</id><content type="html" xml:base="https://ziyuewang25.github.io/blog/2023/DLC-T1-Transformer/"><![CDATA[<p>I started following <a href="https://github.com/jacobhilton/deep_learning_curriculum/tree/master">Deep Learning Curriculum</a> written by <a href="https://www.jacobh.co.uk/">Jacob Hilton</a> and here is what I learnt from the exercise in <a href="https://github.com/jacobhilton/deep_learning_curriculum/blob/master/1-Transformers.md">Topic 1 - Transformer</a>. My solution is written in Colab <a href="https://colab.research.google.com/drive/18oP7mmz6sgC3pUembsOLdS6jSwlVbmIv?usp=sharing">T1-Transformers-solution.ipynb</a></p>

<p>It took me around 20 hours to finish the exercise and it totally worth it. Throughout the process I learnt:</p>
<ol>
  <li>How to implement the transformer model end-to-end.</li>
  <li>How to gather and clean the data for transformer model</li>
  <li>How to implement positional embedding, Attention, FNN, Residual Connection and put all of them together into transformer model.</li>
  <li>Switching between <code class="language-plaintext highlighter-rouge">LayerNorm(x + SubLayer(x))</code> and <code class="language-plaintext highlighter-rouge">x + SubLayer(LayerNorm(x)</code> doesn‚Äôt affect model performance.</li>
  <li>How to program in Pytorch more fluently and gathered a bunch of utility function for later usage.</li>
  <li>How to debug the model by using gradient flow and <code class="language-plaintext highlighter-rouge">torchviz.make_dot</code> to check model structure clearly.</li>
</ol>]]></content><author><name></name></author><category term="AI" /><category term="ML" /><summary type="html"><![CDATA[I tried to replicating the Decoder-only transformer by following "Attention is all you need" paper and trained it on William Shakespeare's work.]]></summary></entry><entry><title type="html">Replicating Diffusion Models on MNIST</title><link href="https://ziyuewang25.github.io/blog/2023/Diffusion-MNIST/" rel="alternate" type="text/html" title="Replicating Diffusion Models on MNIST" /><published>2023-06-11T00:00:00+00:00</published><updated>2023-06-11T00:00:00+00:00</updated><id>https://ziyuewang25.github.io/blog/2023/Diffusion-MNIST</id><content type="html" xml:base="https://ziyuewang25.github.io/blog/2023/Diffusion-MNIST/"><![CDATA[<p>My solution is written in colab <a href="https://colab.research.google.com/drive/1LcxLcVfxeFQWlEEWVTBx_LfNMaY3CoNg?usp=sharing">DiffusionModel-DeepLearningAI-Pytorch.ipynb</a></p>

<p>It took me around 8 hours to implement it and 2 hours are spent on gathering the proper data. Throughout the process I learnt:</p>

<ol>
  <li>The details of DDPM and DDIM algorithm and how diffusion model works</li>
  <li>Manipulating image data for diffusion modeling and demonstration purpose</li>
  <li>classifier-free guided diffusion to let the model generate, <code class="language-plaintext highlighter-rouge">even</code> or <code class="language-plaintext highlighter-rouge">divisible by 3</code> digits.</li>
</ol>]]></content><author><name></name></author><category term="AI" /><category term="ML" /><summary type="html"><![CDATA[I tried to replicating diffusion model (DDPM & DDIM) by following DeepLearningAI course and trained it on MNIST.]]></summary></entry><entry><title type="html">Metrics in Learn-To-Rank (LTR) problems</title><link href="https://ziyuewang25.github.io/blog/2023/Learn-To-Rank-Metrics/" rel="alternate" type="text/html" title="Metrics in Learn-To-Rank (LTR) problems" /><published>2023-04-09T00:00:00+00:00</published><updated>2023-04-09T00:00:00+00:00</updated><id>https://ziyuewang25.github.io/blog/2023/Learn-To-Rank-Metrics</id><content type="html" xml:base="https://ziyuewang25.github.io/blog/2023/Learn-To-Rank-Metrics/"><![CDATA[<p>Suppose we have <code class="language-plaintext highlighter-rouge">Q</code> queries, for each query <code class="language-plaintext highlighter-rouge">q</code>, it brings \(N_q\) results and normally we care about the top <code class="language-plaintext highlighter-rouge">K</code> docs retrieved.</p>

<p>All of the following metric is for 1 query, we need to average them to get an overall score for <code class="language-plaintext highlighter-rouge">Q</code> queries.</p>
<ol>
  <li><code class="language-plaintext highlighter-rouge">Accuracy@K</code>: Whether top K results contain the relevant results.
    <ol>
      <li>Formula: \(A(K)=(\sum_{i=1}^K I(i)) &gt; 0\). \(I(i)\) is an indicator function suggesting whether the \(i_{th}\) position is relevant or not.</li>
    </ol>
  </li>
  <li><code class="language-plaintext highlighter-rouge">Precision@K</code>: How many relevant results among the top K.
    <ol>
      <li>Formula: \(P(K) =\frac{1}{K}\sum_{i=1}^KI(i)\).</li>
      <li>Only for binary cases</li>
    </ol>
  </li>
  <li><code class="language-plaintext highlighter-rouge">Recall@K</code>: How many relevant results among the top K compared with all relevant results.
    <ol>
      <li>Formula: \(R(K) = \frac{1}{m}\sum_{i=1}^KI(i)\). \(m\) is the total number of relevant results overall.</li>
      <li>Only for binary cases</li>
    </ol>
  </li>
  <li><code class="language-plaintext highlighter-rouge">AP@K</code> (Average Precision): the weighted mean of precision at each threshold; the weight is the increase in recall from the prior threshold.
    <ol>
      <li>Formula: \(AP@K = \frac{1}{m}\sum_{k=1}^K P(k)I(k)\)</li>
      <li>A different way to represent \(AP@K\): We can also use <code class="language-plaintext highlighter-rouge">Recall@K</code> here by using its delta format \(\Delta R(k) = R(k) - R(k-1)\). It would be \(\frac{1}{m}\) if a relevant result is at position \(k\), otherwise it is 0. and it becomes \(AP@K = \sum_{k=1}^K P(k) * \Delta R(k)\). In other words, it is the area under Precision-Recall curve.</li>
      <li>Only for binary cases</li>
    </ol>
  </li>
  <li><code class="language-plaintext highlighter-rouge">RR</code> (Reciprocal Rank): reciprocal of the rank of the first relevant item in a ranked list.
    <ol>
      <li>Formula: \(RR = \frac{1}{\text{rank of the first relevant item}}\)</li>
      <li>Only for binary cases.</li>
    </ol>
  </li>
  <li><code class="language-plaintext highlighter-rouge">NDCG@K</code> (Normalized Discounted Cumulative Gain)
    <ol>
      <li><code class="language-plaintext highlighter-rouge">CG@K</code>: Sum of relevance of all results in a search result list \(CG@K = \sum_{k=1}^K rel(k)\), \(rel(k)\) is the relevance score of the result at \(k\).</li>
      <li><code class="language-plaintext highlighter-rouge">DCG@K</code>: Give earlier result higher weights: \(DCG@K = \sum_{k=1}^K\frac{2^{rel(k)} - 1}{ \log_2(k+1)}\)</li>
      <li><code class="language-plaintext highlighter-rouge">NDCG@K</code>: normalize <code class="language-plaintext highlighter-rouge">DCG</code> by its perfect ranking result (a.k.an Ideal <code class="language-plaintext highlighter-rouge">DCG</code> (<code class="language-plaintext highlighter-rouge">IDCG</code>)) to reduce the effect that different search results can vary in length.</li>
    </ol>
  </li>
  <li>Normalized Kendall tau distance at K:
    <ol>
      <li>\(K_n@K(\tau_1, \tau_2) = \frac{K_d}{\frac{1}{2}n(n-1)} = \frac{2}{n(n-1)} \sum_{\{i,j\}\in \mathbb{K}, i &lt; j} \bar K_{i,j}(\tau_1, \tau_2)\). \(\mathbb{K}\) is the set of unordered pairs of distinct elements among the top K in \(\tau_1\) and \(\tau_2\). \(\bar K_{i,j}(\tau_1, \tau_2) = 0\) if \(i\) and \(j\) are in the same order in \(\tau_1\) and \(\tau_2\), otherwise 1.</li>
    </ol>
  </li>
  <li>Spearman Rho:
    <ol>
      <li>Formula: \(\rho = \frac{cov(R(X), R(Y))}{\delta_{R(x)}\delta_{R(Y)}}\)</li>
    </ol>
  </li>
</ol>

<p>Reference:</p>
<ol>
  <li>https://en.wikipedia.org/wiki/Discounted_cumulative_gain</li>
  <li>https://en.wikipedia.org/wiki/Kendall_tau_distance</li>
  <li>https://towardsdatascience.com/normalized-discounted-cumulative-gain-37e6f75090e9</li>
</ol>]]></content><author><name></name></author><category term="AI" /><category term="ML" /><summary type="html"><![CDATA[Suppose we have Q queries, for each query q, it brings \(N_q\) results and normally we care about the top K docs retrieved.]]></summary></entry><entry><title type="html">KDS - Google Universal Image Embedding</title><link href="https://ziyuewang25.github.io/blog/2023/Kaggle-Digestion-Series-1/" rel="alternate" type="text/html" title="KDS - Google Universal Image Embedding" /><published>2023-03-01T00:00:00+00:00</published><updated>2023-03-01T00:00:00+00:00</updated><id>https://ziyuewang25.github.io/blog/2023/Kaggle-Digestion-Series-1</id><content type="html" xml:base="https://ziyuewang25.github.io/blog/2023/Kaggle-Digestion-Series-1/"><![CDATA[<ul>
  <li>Competition End time: 2022-10-17</li>
  <li>Submission Format: notebook &lt;= 9h</li>
</ul>

<h1 id="key-features">Key Features</h1>
<ol>
  <li>No training data provided.</li>
  <li>Ensemble cannot easily work. <a href="https://www.kaggle.com/competitions/google-universal-image-embedding/discussion/340546#1876558]">thread</a></li>
</ol>

<h1 id="evaluation"><a href="https://www.kaggle.com/competitions/google-universal-image-embedding/overview/evaluation">Evaluation</a></h1>
<p>mean Precision @ 5 metric + a small modification to avoid penalizing queries with fewer than 5 expected index images.</p>

\[mP@5 = \frac{1}{Q} \sum_{q=1}^Q \frac{1}{\min(n_q, 5)} \sum_{j=1}^{\min(n_q, 5)} rel_q(j)\]

<ul>
  <li>embedding dimension should be &lt;= 64</li>
  <li>compatible with TensorFlow 2.6.4 or Pytorch 1.11.0</li>
</ul>

<p>The host will use k-NN (k=5) to lookup for each test sample, using the Euclidean distance between test and index embeddings.</p>

<h1 id="data"><a href="https://www.kaggle.com/competitions/google-universal-image-embedding/data">Data</a></h1>
<p><strong>No training data provided.</strong>
Here is the distribution of test data.
<img src="https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F3258%2Fa02c90ad69a049b11a39bd38abcde2cb%2Fdomains.png?generation=1657141626387503&amp;alt=media" alt="" /></p>
<ol>
  <li>External data thread: https://www.kaggle.com/competitions/google-universal-image-embedding/discussion/337384</li>
</ol>

<h1 id="great-notebooks">Great Notebooks</h1>
<ol>
  <li><a href="https://www.kaggle.com/code/motono0223/guie-clip-tensorflow-train-example">CLIP-TF-Train-Example</a>
    <ol>
      <li>CLIP + Arcface + TPU training.</li>
    </ol>
  </li>
  <li><a href="https://www.kaggle.com/code/awsaf49/gcvit-global-context-vision-transformer">GCVIT</a>
    <ol>
      <li>Global Context Vision Transformer</li>
    </ol>
  </li>
  <li><a href="https://www.kaggle.com/code/evilpsycho42/understand-comp-domain-and-imagenet-21k-labels">Understand Comp Domain and ImageNet 21k Labels</a>
    <ol>
      <li>Understanding comp domain and labels</li>
    </ol>
  </li>
</ol>

<h1 id="solutions">Solutions</h1>

<ol>
  <li><a href="https://www.kaggle.com/competitions/google-universal-image-embedding/discussion/359316">1st place solution</a>
    <ol>
      <li>Using <a href="https://www.kaggle.com/competitions/google-universal-image-embedding/discussion/340043">pre-trained weights</a> w/o training or fine-tuning first.</li>
      <li>CLIP <a href="https://github.com/mlfoundations/open_clip">Github</a></li>
      <li><a href="https://arxiv.org/abs/1801.07698">ArcFace</a></li>
      <li>Add datasets to training list <strong>iteratively</strong> to save time and maintain good performance</li>
      <li>unfreeze the backbone after linear head is well trained, so we don‚Äôt need to worry about the random linear head would affect the backbone weights
        <ol>
          <li>use 10 times lower initial learning rate.</li>
          <li>Easy to get overfit and linear projection weights jumped sharply.</li>
          <li>So freeze linear head to train and add dropout to fully connection layer.</li>
        </ol>
      </li>
      <li>Clever ensemble to overcome different F(C, X) issues
        <ol>
          <li>resolution 224 + resolution 280</li>
        </ol>
      </li>
      <li>LAION-5B CLIP Model <a href="https://laion.ai/blog/large-openclip/">blog</a></li>
    </ol>
  </li>
  <li><a href="https://www.kaggle.com/competitions/google-universal-image-embedding/discussion/359525">2nd place solution</a>
    <ol>
      <li>dynamic margin</li>
      <li>stratified learning rate when training non-backbone part.</li>
    </ol>
  </li>
  <li><a href="https://www.kaggle.com/competitions/google-universal-image-embedding/discussion/359487">4th place solution</a></li>
  <li><a href="https://www.kaggle.com/competitions/google-universal-image-embedding/discussion/359161">5th place solution</a></li>
  <li>The rest <a href="https://www.kaggle.com/competitions/google-universal-image-embedding/discussion/359948">thread</a></li>
</ol>]]></content><author><name></name></author><category term="AI" /><category term="Kaggle" /><summary type="html"><![CDATA[Competition End time: 2022-10-17 Submission Format: notebook &lt;= 9h]]></summary></entry><entry><title type="html">Rock Climbing Knowledge - Injuries</title><link href="https://ziyuewang25.github.io/blog/2023/Climbing-Knowledge-Injuries/" rel="alternate" type="text/html" title="Rock Climbing Knowledge - Injuries" /><published>2023-02-25T00:00:00+00:00</published><updated>2023-02-25T00:00:00+00:00</updated><id>https://ziyuewang25.github.io/blog/2023/Climbing-Knowledge-Injuries</id><content type="html" xml:base="https://ziyuewang25.github.io/blog/2023/Climbing-Knowledge-Injuries/"><![CDATA[<p>From my own injury recovery experience, I gradually realize how important it is to warm up. There are many great resources online, so I decide to gather them down here for reference.</p>

<h1 id="pip-joint">PIP Joint</h1>
<ul>
  <li>https://www.camp4humanperformance.com/blog-2/pip-jugs
    <ul>
      <li><strong>high-rate rotational loading is more stressful on the fingers than static loading</strong></li>
      <li>when you can get your middle and distal bones around the edge of the jug, in that context, <strong>most of the stress in the fingers goes into the PIP joint.</strong></li>
      <li>The PIP Joint can suffer from overdoing easy climbing.</li>
      <li>A high volume of easy training can be <strong>counterproductive</strong>.</li>
      <li>PIP swelling are due to
        <ul>
          <li><strong>Collateral ligaments</strong> (sides of the joint)</li>
          <li><strong>A3 pulleys</strong> (hold the tendon close to the joint)</li>
          <li><strong>Volar plate</strong> (ligament across the joint where A3 attaches)</li>
        </ul>
      </li>
      <li><strong>dosage</strong> of stress stype is more important than intensity of the load.</li>
      <li>Treatment:
        <ul>
          <li><strong>Avoid the high-rate rotational loading</strong> for a few weeks to months.</li>
          <li>Don‚Äôt spend weeks to months climbing easy terrain. <strong>Especially in a gym.</strong></li>
          <li>Keep loading your fingers in an <strong>easily trackable way</strong> (ladder style). Fingerboard, campus board (feet on), spray wall etc.</li>
          <li>Be <strong>patient as hell</strong> in rehab! That‚Äôs the not easy part.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>https://www.camp4humanperformance.com/blog-2/pip-joint
    <ul>
      <li>PIP joint accounts for 85% of the motion for grip strength</li>
      <li>a hinge type joint which is stable only in the sagittal plane (flexing and extending)</li>
      <li><img src="https://images.squarespace-cdn.com/content/v1/59d03d018a02c7512bf8b05f/1491d85e-8d95-4c35-ae8e-56977850d9e7/%2311+pip+joint.png?format=750w" alt="" /></li>
      <li><strong>Three grades of collateral ligament injuries</strong></li>
      <li>General recommendations:
        <ul>
          <li><strong>Stiffness and joint contraction</strong> are common with injury.</li>
          <li>There is <strong>no consensus</strong> on best treatment strategies!</li>
          <li>Most injuries <strong>rarely return to full active range of motion.</strong></li>
          <li><strong>Treatment within 4 weeks</strong> is key.</li>
          <li>Immobilization beyond 3 weeks causes <strong>irreversible loss of motion!</strong></li>
          <li><strong>Early diagnosis</strong> and motion are suggested (specifically extensor power).</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>https://www.camp4humanperformance.com/blog-2/finger-pain
    <ul>
      <li><img src="https://images.squarespace-cdn.com/content/v1/59d03d018a02c7512bf8b05f/3e3090bf-516f-4521-a867-961b6c1873fb/%232+Finger+curl.png?format=750w" alt="" /></li>
      <li><strong>Doing something like finger-glides on a regular basis is not necessarily ‚Äúhealthy‚Äù for the joints of your fingers.</strong></li>
      <li>It really comes down to understanding the why behind any intervention. Everything comes with a cost.</li>
    </ul>
  </li>
</ul>

<h1 id="tfcc-injury">TFCC injury</h1>
<ul>
  <li>https://www.camp4humanperformance.com/blog-2/tfcc-injury
    <ul>
      <li><img src="https://images.squarespace-cdn.com/content/v1/59d03d018a02c7512bf8b05f/ae9fdd9a-8406-424d-a5a5-297d1da8fa78/%236+tfcc+injuries.png?format=750w" alt="" /></li>
      <li>Components:
        <ul>
          <li>A triangular shaped <strong>fibro-cartilaginous disc</strong> (shock absorbing, guiding motion)</li>
          <li>Ligaments between the <strong>ulna and radius</strong> on both sides (palmar &amp; dorsal)</li>
          <li>Ligaments between the <strong>ulna and the carpal bones</strong></li>
          <li>A <strong>meniscal type homologoue</strong> (shock absorbing)</li>
          <li>Sub-sheath of the <strong>ECU tendon</strong></li>
        </ul>
      </li>
      <li>Cause: repetitive axial loads to the wrist when the hand is in ulnar deviation and pronation.</li>
      <li>the <strong>dosage</strong> of the stress is the culprit</li>
      <li>Even though it is still recommended to do <strong>conservative management first</strong>, the statistics show that only 1/3 of patients get symptomatic relief. That number is highly dependent on the compliance but does show how tricky these injuries can be.</li>
    </ul>
  </li>
  <li><a href="https://www.memic.com/workplace-safety/safety-net-blog/2019/september/ouch-my-wrist-hurts">TFCC from work</a>
    <ul>
      <li><img src="https://www.memic.com/-/media/memic/images/workplace-safety/blog/2019/power-drills-to-keyboarding-figure-1-jpg/power-drills-to-keyboarding-figure-1-jpg.jpg?la=en&amp;hash=F3141D2EE74CDA2DCA20D9689F5990E33C7D8F4D" alt="" /></li>
    </ul>
  </li>
  <li><a href="https://www.youtube.com/watch?v=lTC3NKENAD8">https://www.youtube.com/watch?v=lTC3NKENAD8</a></li>
  <li>UIS Ulnar Impaction Syndrome
    <ul>
      <li><a href="https://carpaltunnelpros.com/2015/07/10/what-is-ulnar-impaction-syndrome/">What is Ulnar Impaction Syndrome? - Houston Wrist Pain Specialists: Elbow, Hand &amp; Finger Surgery</a></li>
    </ul>
  </li>
  <li>https://www.camp4humanperformance.com/blog-2/wrist-videos
    <ol>
      <li>5:3 x 3 repeater</li>
      <li>30s yielding isotonic</li>
      <li>5s overcoming isotonic</li>
      <li>5 rep isotonic</li>
      <li>velocity isotonic</li>
      <li>1-arm 90-degree PIMA with ulnar deviation</li>
      <li>1-arm 120-degree PIMA with ulnar deviation</li>
      <li>1-arm weighted hammer / band PIMA</li>
      <li>concentric focused ulnar deviation with hammer/band</li>
      <li>rapid concentric ulnar deviation with hammer/band
        <ul>
          <li>Building capacity in this part of the wrist is <strong>essential for staying injury free.</strong></li>
        </ul>
      </li>
    </ol>
  </li>
  <li>https://www.camp4humanperformance.com/blog-2/eccentrics-overprescribed
    <ul>
      <li><img src="https://images.squarespace-cdn.com/content/v1/59d03d018a02c7512bf8b05f/a32e5e47-c99c-4c35-b676-8ea0133e3e68/%238+eccentric+loads.png?format=750w" alt="" /></li>
      <li>Alternative
        <ul>
          <li><strong>Keeping the wrist neutral</strong> will do the same thing (mechanically), and it feels way less risky (good for pain reduction), especially if you‚Äôre an athlete with clicking in the wrist.</li>
          <li><strong>Wrist flexion isometric</strong> (shown on the left). Go heavy and hold for a longer time under tension.</li>
          <li><strong>Wrist extension isometric</strong> (opposite side of the forearm). Same idea.</li>
          <li><strong>Hammer curl isometric.</strong> Curl a heavy dumbbell to 90-degrees at the elbow (thumb up) and hold for time.</li>
          <li><strong>Tricep extension isometric.</strong> Opposite direction. Lower a heavy band or cable machine to 90-degrees (thumb up) and hold for time.</li>
        </ul>
      </li>
      <li>Eccentric flexion over a bench is not a very practical exercise.</li>
      <li>With pain at the wrist, <strong>keeping it neutral is a safe and reliable method.</strong></li>
      <li>This controlled load needs to <strong>change as your rehab progresses.</strong></li>
    </ul>
  </li>
</ul>

<h1 id="a2-pulley-injury">A2 Pulley Injury</h1>
<ul>
  <li>https://www.camp4humanperformance.com/blog-2/pulley-rupture</li>
  <li>https://www.camp4humanperformance.com/blog-2/pulley-injury</li>
</ul>

<h1 id="taping">Taping</h1>
<ul>
  <li>https://www.camp4humanperformance.com/blog-2/finger-taping
    <ul>
      <li>reducing stress to prevent an injury doesn‚Äôt make sense</li>
      <li><strong>taping should be part of progressive rehab plan,</strong> not a method to <em>prevent</em> one.</li>
      <li><img src="https://images.squarespace-cdn.com/content/v1/59d03d018a02c7512bf8b05f/a051125d-57f1-4061-a6fa-702a217606a2/%2329+finger+tape.jpg?format=1500w" alt="" /></li>
      <li>Pros
        <ul>
          <li>provide structural support and reduce pulley stress
            <ul>
              <li>H-tape is good for A2, A3 and A4. but <strong>not collateral ligament and volar plate injuries</strong></li>
            </ul>
          </li>
          <li>provide proprioception (awareness) in the joint</li>
          <li>Modify PIP joint range of motion: make it harder to do full-crimp</li>
          <li>Reduce pain: feels safe and reduces stress and anxiety.</li>
        </ul>
      </li>
      <li>Cons
        <ul>
          <li>not preventative. Listen to the body and back off the volume if it sore</li>
          <li>leads to further overuse.</li>
          <li>modifying ROM for too long can reduce it long-term</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h1 id="general-rehab">General Rehab</h1>
<ul>
  <li>https://www.camp4humanperformance.com/blog-2/random-rehab
    <ul>
      <li>consistency for rehab</li>
      <li>Standardizing warm up - Injury prevention program (IPP): <a href="https://static1.squarespace.com/static/59d03d018a02c7512bf8b05f/t/61f00ab0203e272d1b5f7aa0/1643121335193/Circuit+1.pdf">C1</a>, <a href="https://static1.squarespace.com/static/59d03d018a02c7512bf8b05f/t/61f00ef14ef0dd0b26f75909/1643122431683/Circuit+2.pdf">C2</a>, <a href="https://static1.squarespace.com/static/59d03d018a02c7512bf8b05f/t/61f00f6e8c861241421a2f87/1643122554700/Circuit+3.pdf">C3</a>, <a href="https://static1.squarespace.com/static/59d03d018a02c7512bf8b05f/t/61f00fada2b6c118a65a7ddc/1643122615792/Circuit+4.pdf">C4</a>, <a href="https://static1.squarespace.com/static/59d03d018a02c7512bf8b05f/t/61f0103f1e605f34fe47ea7e/1643122761385/Circuit+5.pdf">C5</a>, <a href="https://static1.squarespace.com/static/59d03d018a02c7512bf8b05f/t/61f0107a2ee7797ce0fd07b2/1643122816517/Circuit+6.pdf">C6</a>
        <ul>
          <li>a new outcome prediction</li>
        </ul>
      </li>
      <li>Rehab loading methods
        <ul>
          <li><img src="https://images.squarespace-cdn.com/content/v1/59d03d018a02c7512bf8b05f/6bdbccd0-378f-4747-903c-dc145d46fb48/%2317+rehab+loading.jpg?format=750w" alt="" /></li>
          <li>then: 30mm for A2, A3 pulleys.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>https://www.camp4humanperformance.com/blog-2/finger-symptoms
    <ul>
      <li><strong>Absence of pain</strong> does not equal health.</li>
      <li><strong>Persistence of pain</strong> does not mean it‚Äôs not healing.</li>
      <li>Connective responds slowly, so <strong>you have to be patient.</strong> ASIDE FROM LOADING AND RECOVERING THERE IS NO METHOD TO MAKE THIS HAPPEN FASTER!</li>
      <li>Not loading at all (under loading) often times is more stressful for athletes. <strong>There are always things you can do!</strong></li>
      <li>Get help from a <strong>professional</strong>.</li>
    </ul>
  </li>
  <li>https://www.camp4humanperformance.com/blog-2/unique-finger
    <ul>
      <li><img src="https://images.squarespace-cdn.com/content/v1/59d03d018a02c7512bf8b05f/39d7cb97-8afd-468d-a2f4-24f46ac3eedb/%234.1.png?format=500w" alt="" /></li>
      <li><img src="https://images.squarespace-cdn.com/content/v1/59d03d018a02c7512bf8b05f/fda71a5a-ee5f-4d5d-bf3d-4d61778c4a09/%234.2.png?format=500w" alt="" /></li>
      <li>There are <strong>fewer rules with finger training</strong> than you likely think. Using a bigger edge to make your fingers stronger is totally acceptable.</li>
    </ul>
  </li>
</ul>]]></content><author><name></name></author><category term="Life" /><category term="Climbing" /><summary type="html"><![CDATA[Rock Climbing related injuries knowledge sharing.]]></summary></entry><entry><title type="html">Kaggle Digestion Series</title><link href="https://ziyuewang25.github.io/blog/2023/Kaggle-Digestion-Series/" rel="alternate" type="text/html" title="Kaggle Digestion Series" /><published>2023-02-25T00:00:00+00:00</published><updated>2023-02-25T00:00:00+00:00</updated><id>https://ziyuewang25.github.io/blog/2023/Kaggle-Digestion-Series</id><content type="html" xml:base="https://ziyuewang25.github.io/blog/2023/Kaggle-Digestion-Series/"><![CDATA[<p>I always found Kaggle competition quite fascinating because the problems are interesting and various a lot. We can always learn some new tricks and gain some valuable insights from each competition. Since most of the comps are real-life cases, it is also quite practical and meaningful to handle them well. Since I found participating in each comp and getting a gold medal can usually take quite long time (&gt;100 hours). I decide to actually step back and learn from those comps by reading through the discussion and notebook after the comp has finished. Let‚Äôs see how much we can gain from this journey. Hope we will find something valuable through this series as well.</p>

<p>The main things I wanna know from each competition is:</p>
<ol>
  <li>What‚Äôs special about the data?</li>
  <li>How to understand the data better?</li>
  <li>What model works?</li>
  <li>What competition tricks work?</li>
</ol>]]></content><author><name></name></author><category term="AI" /><category term="Kaggle" /><summary type="html"><![CDATA[I always found Kaggle competition quite fascinating because the problems are interesting and various a lot. We can always learn some new tricks and gain some valuable insights from each competition. Since most of the comps are real-life cases, it is also quite practical and meaningful to handle them well. Since I found participating in each comp and getting a gold medal can usually take quite long time (&gt;100 hours). I decide to actually step back and learn from those comps by reading through the discussion and notebook after the comp has finished. Let‚Äôs see how much we can gain from this journey. Hope we will find something valuable through this series as well.]]></summary></entry><entry><title type="html">2022 Year Reflection</title><link href="https://ziyuewang25.github.io/blog/2022/Year-Reflection/" rel="alternate" type="text/html" title="2022 Year Reflection" /><published>2022-12-31T00:00:00+00:00</published><updated>2022-12-31T00:00:00+00:00</updated><id>https://ziyuewang25.github.io/blog/2022/Year%20Reflection</id><content type="html" xml:base="https://ziyuewang25.github.io/blog/2022/Year-Reflection/"><![CDATA[<blockquote>
  <p>The unexamined life is not worth living ‚ÄìSocrates</p>
</blockquote>

<p>Reflecting back on 2022, I experienced a lot, both outside and inside:</p>

<ol>
  <li>
    <p>I changed my job from quant üí∞ at BNP to software engineer üñ•Ô∏è at Google.</p>
  </li>
  <li>
    <p>I moved from New York üóΩ to Seattle üóª.</p>
  </li>
  <li>
    <p>I met many awesome friends from climbing, working and friends.</p>
  </li>
  <li>
    <p>I bought my first car üöó and it really changed my way of living.</p>
  </li>
  <li>
    <p>I switched from omnivore üçñ to Veggan ü•¶ (Vegan + Egg). Today is my 117 days since my last meat bite and I felt very good to see a lower footprint and a contribution to animal protection.</p>
  </li>
  <li>
    <p>I become a husband, legally. üòÄ</p>
  </li>
  <li>
    <p>I traveled with my wife together to San Jose, San Francisco, Yosemite and Vancouver.</p>
  </li>
  <li>
    <p>I start consistently doing meditation üßò in the morning and I have meditated for around 38.6 hours.</p>
  </li>
  <li>
    <p>I start consistently reading books üìö. I have read and summarized 38 books since the beginning of this year and here is my goodreads <a href="http://goodreads.com/vincentwang">profile</a>.</p>
  </li>
  <li>
    <p>I wrote an open-source <a href="https://github.com/VincentWang25/USVisaAppointment">program</a> üßë‚Äçüíª to get US visa appointment slots and successfully got my visa stamped in Canada.</p>
  </li>
  <li>
    <p>I got a Kaggle competition gold medal üèÖ on February and wrote a <a href="https://www.kaggle.com/competitions/tensorflow-great-barrier-reef/discussion/307718">post</a> to summarize our methods.</p>
  </li>
  <li>
    <p>I started reading papers seriously and upgraded my note-taking system by following <a href="https://reasonabledeviations.com/2022/04/18/molecular-notes-part-1/">Molecular Notes</a> and <a href="https://www.buildingasecondbrain.com/">Building a Second Brain</a>. I can‚Äôt wait to see it scale up üòÄ</p>
  </li>
  <li>
    <p>I almost stopped using social media, like WeChat and Instagram. I freed myself for more time to enjoy what was truly worth my attention.</p>
  </li>
  <li>
    <p>I changed from doing rock climbing crazily into injury recovery mode. I became more patient and a long-term viewer from this one. But before the injury, I got my first single arm open hand 20mm 5s hang (that‚Äôs something probably only climbers can understand üòÖ)</p>
  </li>
</ol>

<p>Overall I felt proud and happy about these changes. I felt more controlled about myself and motivated every day to enjoy my life. As failure needs reflection to be avoided in the future, success needs it as well to keep the momentum. I would say the following 3 habits/methods really helped me to become the person I wanna be.</p>

<h1 id="1-reading">1 Reading</h1>

<blockquote>
  <p>ÂºÄÂç∑ÊúâÁõä (Reading enriches the mind) ‚Äî‚Äî „Ää‰∏éÂ≠ê‰ø®Á≠âÁñè„Äã</p>
</blockquote>

<p>I intentionally set the <strong>1 hour before bedtime</strong> as my reading hour, it helps me <strong>wind down for the day</strong> and <strong>step into a different world</strong> by following the books. I like reading non-fiction books since I enjoy learning new knowledge from them. I agree with this <a href="https://reasonabledeviations.com/2022/01/24/reading-philosophy/">post</a> regarding how to read a nonfiction book and I kept <strong>extracting the wisdom from books into my life</strong>. Luckily, my wife also enjoys reading books and it is really nice time to read books together in a relaxed mode. I listed a few books that helped me in different fields.</p>

<ul>
  <li>
    <p>Productivity:</p>

    <ul>
      <li>
        <p><a href="https://www.goodreads.com/book/show/22544758-triggers">Triggers: Creating Behavior That Lasts‚ÄîBecoming the Person You Want to Be</a></p>
      </li>
      <li>
        <p><a href="https://www.goodreads.com/book/show/2250.The_7_Habits_of_Highly_Effective_People_Personal_Workbook">The 7 Habits of Highly Effective People Personal Workbook</a></p>
      </li>
      <li>
        <p><a href="https://www.goodreads.com/book/show/25744928-deep-work">Deep Work: Rules for Focused Success in a Distracted World</a></p>
      </li>
      <li>
        <p><a href="https://www.goodreads.com/book/show/40121378-atomic-habits">Atomic Habits: An Easy &amp; Proven Way to Build Good Habits &amp; Break Bad Ones</a></p>
      </li>
    </ul>
  </li>
  <li>
    <p>Relax and be healthy:</p>

    <ul>
      <li>
        <p><a href="https://www.goodreads.com/book/show/24019187-humans-of-new-york">Humans of New York: Stories</a></p>
      </li>
      <li>
        <p><a href="https://www.goodreads.com/book/show/35457841-the-4-pillar-plan">The 4 Pillar Plan: How to Relax, Eat, Move, Sleep Your Way to a Longer, Healthier Life</a></p>
      </li>
      <li>
        <p><a href="https://www.goodreads.com/book/show/34466963-why-we-sleep">Why We Sleep: Unlocking the Power of Sleep and Dreams</a></p>
      </li>
      <li>
        <p><a href="https://www.goodreads.com/book/show/23846205-how-to-relax">How to Relax</a></p>
      </li>
      <li>
        <p><a href="https://www.goodreads.com/book/show/48307.Becoming_Vegan">Becoming Vegan: The Complete Guide to Adopting a Healthy Plant-Based Diet</a></p>
      </li>
      <li>
        <p><a href="https://www.goodreads.com/book/show/22392738-the-rock-climber-s-training-manual-a-guide-to-continuous-improvement">The Rock Climber‚Äôs Training Manual - A Guide to Continuous Improvement</a></p>
      </li>
    </ul>
  </li>
  <li>
    <p>Communicate:</p>

    <ul>
      <li><a href="https://www.goodreads.com/book/show/3601593-non-violent-communication-a-language-of-life">Non Violent Communication A Language of Life</a>,</li>
    </ul>
  </li>
  <li>
    <p>Be financially secure:</p>

    <ul>
      <li>
        <p><a href="https://www.goodreads.com/book/show/40491946-financial-freedom">Financial Freedom: A Proven Path to All the Money You Will Ever Need</a></p>
      </li>
      <li>
        <p><a href="https://www.goodreads.com/book/show/41881472-the-psychology-of-money">The Psychology of Money</a></p>
      </li>
    </ul>
  </li>
  <li>
    <p>Find meaning in my life:</p>

    <ul>
      <li><a href="https://www.goodreads.com/book/show/38210.The_Art_of_Happiness">The Art of Happiness</a></li>
    </ul>
  </li>
  <li>
    <p>Learn:</p>

    <ul>
      <li><a href="https://www.goodreads.com/book/show/18770267-make-it-stick">Make It Stick: The Science of Successful Learning</a></li>
    </ul>
  </li>
  <li>
    <p>Understand the world:</p>

    <ul>
      <li>
        <p><a href="https://www.goodreads.com/book/show/40933227-factfulness">Factfulness: Ten Reasons We‚Äôre Wrong About the World ‚Äì and Why Things Are Better Than You Think</a></p>
      </li>
      <li>
        <p><a href="https://www.goodreads.com/book/show/33585392-dear-ijeawele-or-a-feminist-manifesto-in-fifteen-suggestions">Dear Ijeawele, or a Feminist Manifesto in Fifteen Suggestions</a></p>
      </li>
    </ul>
  </li>
  <li>
    <p>Gain knowledge in my interested fields:</p>

    <ul>
      <li>
        <p><a href="https://www.goodreads.com/book/show/55275019-machine-learning-design-patterns">Machine Learning Design Patterns: Solutions to Common Challenges in Data Preparation, Model Building, and MLOps</a></p>
      </li>
      <li>
        <p><a href="https://www.goodreads.com/book/show/3735293-clean-code">Clean Code: A Handbook of Agile Software Craftsmanship</a></p>
      </li>
      <li>
        <p><a href="https://www.goodreads.com/book/show/23463279-designing-data-intensive-applications">Designing Data-Intensive Applications</a></p>
      </li>
      <li>
        <p><a href="https://www.goodreads.com/book/show/60715378-designing-machine-learning-systems">Designing Machine Learning Systems: An Iterative Process for Production-Ready Applications</a></p>
      </li>
      <li>
        <p><a href="https://www.goodreads.com/book/show/4099.The_Pragmatic_Programmer">The Pragmatic Programmer: From Journeyman to Master</a></p>
      </li>
      <li>
        <p><a href="https://www.goodreads.com/book/show/59694883-deep-learning-in-production">Deep Learning in Production</a></p>
      </li>
    </ul>
  </li>
</ul>

<h1 id="2-tracking--scoring">2 Tracking &amp; Scoring</h1>

<blockquote>
  <p>The first step toward change is awareness. The second step is acceptance. ‚ÄîNathaniel Branden</p>
</blockquote>

<p>I started tracking how I spent my week since January 1st and it helps me reflect upon <strong>how I was doing last week</strong> and <strong>figure out the plan for next week</strong>. It redirects my focus and tracks me to see how far I am away from mastery (10,000 hours). I listed a few identities as my goals (according to <a href="https://www.goodreads.com/book/show/2250.The_7_Habits_of_Highly_Effective_People_Personal_Workbook">The 7 Habits of Highly Effective People</a>) and another column named ‚Äúwasted time‚Äù to track how I spend my week. Those goals can remind me of what kind of person I wanna be in the long run. The ‚Äúwasted time‚Äù is usually some meaningless screen time watching youtube videos or short videos, they are sometimes really disturbing. I want to maximize my time on goal and minimize the ‚Äúwasted time‚Äù.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/WeeklyHours-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/WeeklyHours-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/WeeklyHours-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/WeeklyHours.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>

<p>To be specific, we have 24 hours per day, excluding 8 hours of sleep and 3 hours of necessary activities (eating, dressing up and etc), we are left with <strong>13 hours</strong>. For a week, we will have 13 * 7 = <strong>91 hours</strong>. It is not much. If we deduct working hours (7 * 5), it only left us with <strong>56 hours</strong> and we need to use that time to spend with our family, personal hobbies, and some wild dreams ‚≠ê. Here is a decomposition of my time.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/HoursUsedSectors-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/HoursUsedSectors-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/HoursUsedSectors-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/HoursUsedSectors.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>

<p>Even though I tried to record the time I spend on each goal, sometimes it is still hard to track since I might just do some misc stuff like commuting or daydreaming ü§£. I am glad to see a high ratio of ‚ÄúWork / Research Engineer‚Äù, ‚ÄúProfessional Climber‚Äù and ‚ÄúSpouse, Friends, Son‚Äù. They are part of my core identity. Note there that I listed ‚ÄúSpouse, Friends, Son‚Äù as part of my time tracking because they are important, never less than ‚ÄúWork / Research Engineer‚Äù. Having them here kept me balanced and my goal is not solely about being a great research engineer but to be happy (I agree with the meaning of life mentioned in <a href="https://www.goodreads.com/book/show/38210.The_Art_of_Happiness">Happiness</a>).</p>

<p>I used <a href="https://clockify.me/">clockify</a> to <strong>track my time blocks every day</strong> and used google Sheets to record my weekly data. It is part of my weekly reflection routine and helped me stay on track.</p>

<p>Since October, after reading <a href="https://www.goodreads.com/book/show/22544758-triggers">Triggers</a>, I started using a <strong>scoring method</strong> mentioned to do daily reflection. They are self-evaluations regarding questions like ‚Äú<strong>Did I do my best to ‚Ä¶</strong>‚Äù (eg prioritize, meditate, sit in good posture and etc). Compared with other evaluations, this kind of question reminds me that <strong>I have control over my behavior and I shouldn‚Äôt blame anyone else if a certain desire is unmet</strong>. I will report the scores every day to my wife to make them accountable. (Thank you, my wife, you are a great listener!)</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/DailyScore-480.webp" />
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/DailyScore-800.webp" />
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/DailyScore-1400.webp" />
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/DailyScore.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();" />

  </picture>

</figure>

    </div>
</div>

<p>The score here is an average of several items during the day. Some days are good, and some are bad. Some habits are hard to get rid of or acquire while some don‚Äôt take that long. Doing daily reflection also helps me <strong>stay on track with my goal and progression</strong>. I normally will feel proud if I can score 90+ and feel a bit frustrated if it is lower than 80. This scoring method can also help me <strong>find the pattern and reflect upon when my willpower is the weakest</strong>. For example, I found myself easily getting hooked on excessive phone usage after dinner, so I learned to keep my phone away before dinner. If some items consistently score high after several weeks, then I have a strong belief that it becomes my habit and can be removed from my daily reflection score system.</p>

<h1 id="3-triggering-good-habits-and-avoiding-bad-ones">3 Triggering good habits and avoiding bad ones</h1>

<blockquote>
  <p>We are what we repeatedly do. Excellence, then, is not an act, but a habit. ‚Äî Aristotle</p>
</blockquote>

<p>I used to be got distracted by social media and short videos a lot and they are habits I want to get rid of. I even tested myself that ‚ÄúI will only watch one clip of a short video‚Äù then I opened the app, and after 1 hour, I realized that I can‚Äôt stop. Our willpower is limited and we need some help to deal with various distractions in our modern world.</p>

<p>That‚Äôs why I decided to follow the methods mentioned in <a href="https://www.goodreads.com/book/show/40121378-atomic-habits">Atomic Habits</a> and <strong>make the bad habits hard to do</strong>. I went crazy: I hid all my friends‚Äô moments on WeChat so whenever I opened the friend circle, there is no new feeds. I put my phone somewhere hard to reach, so I don‚Äôt need to worry about myself using it when my willpower is low. By using this method, my screen time went down quite a lot and allowed me more time to do the things I love/need to do.</p>

<p>I also tried to <strong>make the good habits easy or fun to do</strong>. For example, for meditation, I bought a <a href="https://a.co/d/3M46Am1">Digital Finger Counter</a> so my daily meditation becomes easier to follow. Seeing the counter also makes the time more visible and helps me make progress over time.</p>

<h1 id="remarks">Remarks</h1>

<blockquote>
  <p>Most people overestimate what they can do in one year and underestimate what they can do in ten years. ‚Äî Bill Gates</p>
</blockquote>

<p>I am lucky to have the chance to fully experience 2022 and find my happiness level higher than before.</p>

<p>The road to happiness is blocked by our ignorance and lack of knowledge. We are often told what to do, and what is expected, and born with the constraint of our culture. I used this post as a reflection and a wish to help you find something useful, to <strong>enable your possibility of less suffering and more happiness</strong>.</p>

<p>Coping from what Robert said: ‚ÄúWriting about personal productivity always feels somewhat self-indulgent; it inevitably comes down to ‚Äòthis is how I do things ‚Äì you should do it too!‚Äô.‚Äù That‚Äôs not my intention and what I suggested here is only a reference or I should say something that works for me. I hope it can help you but it may not üòÉ</p>

<p>Time is limited. Attention is also limited. To do something great requires persistence and consistency. Luckily, we still have time and when we can focus our attention on those truly important things, they will come, eventually üòâ</p>

<p>Cheers,</p>

<p>Ziyue</p>

<p>2022-12-31</p>]]></content><author><name></name></author><category term="Life" /><category term="Reflection" /><summary type="html"><![CDATA[What I learnt from 2022 experience.]]></summary></entry></feed>