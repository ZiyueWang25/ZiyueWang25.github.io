<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://ziyuewang25.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://ziyuewang25.github.io/" rel="alternate" type="text/html" hreflang="en" /><updated>2023-08-02T01:26:52+00:00</updated><id>https://ziyuewang25.github.io/feed.xml</id><title type="html">blank</title><subtitle>Think -&gt; Experiment -&gt; Create -&gt; Serve :)
</subtitle><entry><title type="html">ARENA learning experience</title><link href="https://ziyuewang25.github.io/blog/2023/ARENA/" rel="alternate" type="text/html" title="ARENA learning experience" /><published>2023-08-01T00:00:00+00:00</published><updated>2023-08-01T00:00:00+00:00</updated><id>https://ziyuewang25.github.io/blog/2023/ARENA</id><content type="html" xml:base="https://ziyuewang25.github.io/blog/2023/ARENA/"><![CDATA[<p>I found <a href="https://github.com/callummcdougall/ARENA_2.0">ARENA</a> quite helpful for self-study AI safety related topics and it can work well in together with <a href="https://github.com/jacobhilton/deep_learning_curriculum">Deep Learning Curriculum</a>. It offers colab choice for the exercise part, which is great since I don’t have much GPU support for my own computer.</p>

<p>Here is how I spent my time on various topics in ARENA and hope it can work as a reference for someone also interested in self-studying this material.</p>

<p>Total Hours: 32.7. Split into the following:</p>
<ul>
  <li>8.7h <a href="https://arena-ch0-fundamentals.streamlit.app/">Chapter 0: Fundamentals</a>
    <ul>
      <li>skipped  exercise 0.1 <a href="https://arena-ch0-fundamentals.streamlit.app/[0.1]_Ray_Tracing">Ray Tracing</a> since I found it too advanced to be necessary.</li>
      <li>2.3h exercise 0.2 <a href="https://colab.research.google.com/drive/1tmwlA1YQIrgXblzo_9q2mNvEOuAqsV3N?usp=sharing">CNN</a>. I learnt about <code class="language-plaintext highlighter-rouge">torch.as_strided</code> related stuff.</li>
      <li>2.4h exercise 0.3 <a href="https://colab.research.google.com/drive/1gnUiIAzIvjYvaUXdZP7J8e_n1qeLhHFj?usp=sharing">Resnet</a>. I learnt a more detailed view about resnet, pytorch_lighting, batchnorm.</li>
      <li>2.0h exercise 0.4 <a href="https://colab.research.google.com/drive/1HjzmCYqBVz_Q0XVj0mmOZGV26tW1WvHi?usp=sharing">Optimization</a>. I learnt about details of various optimizer, <code class="language-plaintext highlighter-rouge">Weight &amp; Bias</code> related usage.</li>
      <li>2.0h  exercise 0.5 <a href="https://colab.research.google.com/drive/1WjtXIlpr3iC5fPGC4_hGSm6nYMdIptNc?usp=sharing">Backprop</a> (skipped part 3 &amp; 4 &amp; 5). I learnt about details of back propagation &amp; Autograd.</li>
    </ul>
  </li>
  <li>8.0h <a href="https://arena-ch1-transformers.streamlit.app/">Chapter 1: Transformers &amp; Mech Interp</a>
    <ul>
      <li>3.0h  exercise 1.1 <a href="https://colab.research.google.com/drive/1Ig779Od-OoO8lHolRqWQTaAvhK98EdJT?usp=sharing">transformer</a> (I skipped part of sampling.). I learnt about details of transformer, sampling, training and inference sampling.</li>
      <li>5.0h  exercise 1.2 <a href="https://colab.research.google.com/drive/1NfLlt3McxOK9eY4xT_S6Q0ZFaoXtrW2B?usp=sharing">mechanistic interpretability</a>. I learnt about induction circuits, transformerLens, induction heads, hooks, reverse-engineering induction circuits. These material opened a new view for me about how to understand LLM. I find some part hard to understand though and skipped some of the exercise as I don’t want to spend too much time on this topic for now.</li>
    </ul>
  </li>
  <li>16.0h <a href="https://arena-ch2-rl.streamlit.app/">Chapter 2: Reinforcement Learning</a>
    <ul>
      <li>2.5h  exercise 2.1 <a href="https://arena-ch2-rl.streamlit.app/">Introduction to RL</a>. it works like a memory refresher about some RL concepts. It is nice to check the detail of some RL environments.</li>
      <li>7.0h  exercise 2.2 <a href="https://arena-ch2-rl.streamlit.app/">Deep Q Learning</a></li>
      <li>4.0h  exercise 2.3 <a href="https://colab.research.google.com/drive/1UlhPmIfhQLo_10r5OkDwLxWF--A2iCKc?usp=sharing">PPO</a>. The Atari Breakout game result is shown <a href="https://wandb.ai//vincentwang25/PPOAtari/reports/videos-23-07-18-13-10-22---Vmlldzo0OTA1MjM0">here</a>.</li>
      <li>2.5h  exercise 2.4 <a href="https://arena-ch2-rl.streamlit.app/[2.4]_RLHF">RLHF</a>.</li>
    </ul>
  </li>
</ul>]]></content><author><name></name></author><category term="AI" /><category term="ML" /><summary type="html"><![CDATA[I summarized my learning experience about ARENA.]]></summary></entry><entry><title type="html">How to get gold medal in Kaggle competition, from a Competition Master perspective.</title><link href="https://ziyuewang25.github.io/blog/2023/win-thoughts/" rel="alternate" type="text/html" title="How to get gold medal in Kaggle competition, from a Competition Master perspective." /><published>2023-07-29T00:00:00+00:00</published><updated>2023-07-29T00:00:00+00:00</updated><id>https://ziyuewang25.github.io/blog/2023/win-thoughts</id><content type="html" xml:base="https://ziyuewang25.github.io/blog/2023/win-thoughts/"><![CDATA[<p>I started doing Kaggle competition seriously since 2021 February and became Kaggle Competition Master on 2022 March. During that 1 year, I have won 2 gold, 1 silver and 2 bronze medals.</p>

<p><img src="https://i.ibb.co/MBHJMmG/2023-07-29-15-40.png" alt="" /></p>

<p>Here is my 7 suggestions about how to win a Competition:</p>

<ol>
  <li>
    <p>Hard work: the competition I participated in usually takes me around 200 hours to get a decent result (Silver +). Definitely, the time needed can be lower with more experience.</p>
  </li>
  <li>
    <p>Teamwork: teaming up with experienced people can boost the learning process and also get a higher chance to win</p>
  </li>
  <li>
    <p>Jump out of local optimum: don’t spend too much time on hyperparameter tuning or small model structure tuning but rather put more data on data investigation, feature engineering, and very different model structure.</p>
  </li>
  <li>
    <p>Good pipeline: preprocess -&gt; model training -&gt; post-process, machine learning pipeline can be complex but having a good pipeline is essential because it allows more experiments and thus gives a higher chance to hit the lucky spot.</p>
  </li>
  <li>
    <p>Good Cross-Validation setting: Having a good CV setting can be great to find the right direction to go fast. Relying on Public LB can be sometimes quite dangerous and slow.</p>
  </li>
  <li>
    <p>Curiosity: Having enough interest in the competition is probably the main driven motivation for me to push higher and higher scores.</p>
  </li>
  <li>
    <p>Learning one topic at a time: don’t get overwhelmed by too much information at one time, just take one discussion post or one kernel to learn. We will catch up in the end with enough time. Playing Kaggle is not like horse racing but rather a research process.</p>
  </li>
</ol>

<p>Hope this can be helpful to some extent. Let me know if there is anything else you are interested!</p>]]></content><author><name></name></author><category term="AI" /><category term="ML" /><category term="Kaggle" /><summary type="html"><![CDATA[I summarized 7 key points about how to get a Kaggle competition gold medal.]]></summary></entry><entry><title type="html">Implementing PPO from scratch</title><link href="https://ziyuewang25.github.io/blog/2023/DLC-T6-RL/" rel="alternate" type="text/html" title="Implementing PPO from scratch" /><published>2023-07-23T00:00:00+00:00</published><updated>2023-07-23T00:00:00+00:00</updated><id>https://ziyuewang25.github.io/blog/2023/DLC-T6-RL</id><content type="html" xml:base="https://ziyuewang25.github.io/blog/2023/DLC-T6-RL/"><![CDATA[<p>I started following <a href="https://github.com/jacobhilton/deep_learning_curriculum/tree/master">Deep Learning Curriculum</a>(DLC) written by <a href="https://www.jacobh.co.uk/">Jacob Hilton</a> and here is what I experienced and learnt from the exercise in <a href="https://github.com/jacobhilton/deep_learning_curriculum/blob/master/6-Reinforcement-Learning.md">Topic 6 - Reinforcement Learning</a>. My solution is written in Colab <a href="https://colab.research.google.com/drive/1n8EhT0RHxdS1MIgiPQkvjDX7sD7Mpxoy?usp=sharing">T6-RL-solution.ipynb</a></p>

<p>It took me around 40 hours to finish the exercise. I started by spending around 15 hours doing the exercise in <a href="https://github.com/callummcdougall/ARENA_2.0/tree/main">ARENA</a> about RL to get myself familiar with different components in RL and then spending the rest 25 hours doing the DLC exercise.</p>

<p>I referred to the ARENA’s exercise solution heavily since I have done them. To implement and debug the RL algorithm, I referred to posts <a href="https://andyljones.com/posts/rl-debugging.html">Debugging RL, Without the Agonizing Pain</a> and <a href="https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/">The 37 Implementation Details of Proximal Policy Optimization</a>.</p>

<p>I used Colab Pro+ environment to enable background running and more compute. The experimentation is done using 1 V100 GPU.</p>

<p>I have generated the  Result <a href="https://wandb.ai/vincentwang25/PPOProcgen/reports/PPO-Implementation-in-Procgen-Env--Vmlldzo0OTQ3NzE5?accessToken=s9w0lpjb2fjv77ouf1c7nrb2s0zcviymc0mmw8pksr34mnsiblw5x7t7izv5gbhs">Report</a> in Weights &amp; Bias. It shows</p>

<ol>
  <li>Increasing amount of episode return</li>
  <li>reasonable amount of ratios clipped by PPO.</li>
  <li>Small and fairly stable approximate KL.</li>
  <li>Policy entropy (relative entropy) falls gradually</li>
  <li>Value residual Variance (1 - value explained variance) tend to something positive.</li>
  <li>Mean and standard deviation for advantage normalization are fairly stable and mean is pretty close to zero.</li>
</ol>

<p><img src="https://i.ibb.co/9rkgjbc/2023-07-23-09-12.png" alt="" /></p>

<p><img src="https://i.ibb.co/nQzcTBs/2023-07-23-09-13.png" alt="" /></p>

<p>Another closer look at the episode return. It shows that using IMPALA model performs better than traditional CNN, especially at <code class="language-plaintext highlighter-rouge">bigfish</code> environment.</p>

<p><img src="https://i.ibb.co/2g1Pjfd/2023-07-23-09-16.png" alt="" /></p>

<p>Other than these results, I found implementing the PPO algorithm under customized easy probing environments quite helpful. It is also helpful to achieve decent performance under CartPole environment and Atari environments before moving into harder Procgen Environments.</p>

<p>Extensively track the metrics can also be helpful to debug where things went wrong or well, though relying on some of them solely might be inadequate. I am confused by <a href="https://andyljones.com/posts/rl-debugging.html#:~:text=handling%20invalid%20actions.-,Residual%20variance,-The%20variance%20of">residual variance</a> oscillation inside CartPole environment before, i.e. the residual variance doesn’t go smoothly towards a positive value, but <a href="https://wandb.ai//vincentwang25/PPOCart/reports/PPO-CartPPO-CartPole-Wrong-Value-Residual-Variance--Vmlldzo0OTE1NTcw?accessToken=jb0t273joya2ec1a4xaiefydzhb5qd0h1wekl40yo55cr9r6mcz6t25ibj0otim4">oscillate wildly</a>. It turns out that this can be due to the inherent simplicity of the CartPole environment: it doesn’t need much value estimation, but more relying on planning. This cause the value estimation to be unstable.</p>

<p>Overall I found this exercise quite helpful for me to understand the PPO algorithm and generally RL algorithm structure.</p>]]></content><author><name></name></author><category term="AI" /><category term="ML" /><summary type="html"><![CDATA[I tried to implementing PPO from scratch and apply it to Procgen environment. Here is what I learnt.]]></summary></entry><entry><title type="html">Replicating Scaling Laws by using MNIST data</title><link href="https://ziyuewang25.github.io/blog/2023/DLC-T2-Scaling-Laws/" rel="alternate" type="text/html" title="Replicating Scaling Laws by using MNIST data" /><published>2023-07-10T00:00:00+00:00</published><updated>2023-07-10T00:00:00+00:00</updated><id>https://ziyuewang25.github.io/blog/2023/DLC-T2-Scaling%20Laws</id><content type="html" xml:base="https://ziyuewang25.github.io/blog/2023/DLC-T2-Scaling-Laws/"><![CDATA[<p>I started following <a href="https://github.com/jacobhilton/deep_learning_curriculum/tree/master">Deep Learning Curriculum</a> written by <a href="https://www.jacobh.co.uk/">Jacob Hilton</a> and here is what I learnt from the exercise in <a href="https://github.com/jacobhilton/deep_learning_curriculum/blob/master/2-Scaling-Laws.md">Topic 2 - Scaling Laws</a>. My solution is written in Colab <a href="https://colab.research.google.com/drive/1xTpfj6xADQYdUudnZE9AWMUzyr8DBoU6?usp=sharing">T2-ScalingLaws-solution.ipynb</a></p>

<p>It took me around 15 hours to finish the exercise. Throughout the process I learnt:</p>
<ol>
  <li>How to vary the CNN width and training data to follow scaling laws experimentation set up.</li>
  <li>How to use Pytorch lighting learning rate finder to adjust the learning rate based on model size.
    <ol>
      <li>use <code class="language-plaintext highlighter-rouge">callbacks.LearningRateFinder</code> from pytorch lighting and do some experimentation to find the proper minimum and maximum learning rate to search from. Plot the learning rate to make sure the result looks right. <img src="https://i.ibb.co/BBN4gyc/lr-plot.png" alt="" /></li>
    </ol>
  </li>
  <li>How the compute-efficient model size varies with compute.
    <ol>
      <li>To approximate the relationship between compute and loss, we can use <a href="https://www.cuemath.com/calculus/cube-root-function/">Cubic Root Function</a>. We need to train more episodes to enable an accurate approximation.</li>
    </ol>
  </li>
</ol>

<p><img src="https://i.ibb.co/41vg6jL/download-2.png" alt="" /></p>

<p><img src="https://i.ibb.co/zNDhTpD/download.png" alt="" />
<img src="https://i.ibb.co/dgSp0MN/download-1.png" alt="" /></p>]]></content><author><name></name></author><category term="AI" /><category term="ML" /><summary type="html"><![CDATA[I tried to replicating scaling laws result by using MNIST data. Here is what I learnt.]]></summary></entry><entry><title type="html">Find the induction heads in GPT-2</title><link href="https://ziyuewang25.github.io/blog/2023/DLC-T1-MI/" rel="alternate" type="text/html" title="Find the induction heads in GPT-2" /><published>2023-06-28T00:00:00+00:00</published><updated>2023-06-28T00:00:00+00:00</updated><id>https://ziyuewang25.github.io/blog/2023/DLC-T1-MI</id><content type="html" xml:base="https://ziyuewang25.github.io/blog/2023/DLC-T1-MI/"><![CDATA[<p>I started following <a href="https://github.com/jacobhilton/deep_learning_curriculum/tree/master">Deep Learning Curriculum</a> written by <a href="https://www.jacobh.co.uk/">Jacob Hilton</a> and here is what I learnt from the exercise in <a href="https://github.com/jacobhilton/deep_learning_curriculum/blob/master/8-Interpretability.md">Topic 8 - Interpretability</a>. My solution is written in Colab <a href="https://colab.research.google.com/drive/15CSZ09T0LQ4_BAM7_NcGDy5sTVneFJQw?usp=sharing">T8-Interpretability-solution.ipynb</a></p>

<p>It took me around 8 hours to finish the exercise and most of the time is spent on <a href="https://github.com/callummcdougall/ARENA_2.0">ARENA</a> course material about this topic. It helps me a lot in understanding this topic and it offers many helper functions to do this exercise. Here is what I learnt from this exercise:</p>
<ol>
  <li><strong>Induction head</strong>: A head which implements the induction behavior. They attend to the token immediately after an earlier copy of the current token, and then predicts that the token attended to will come next.</li>
  <li>How to reverse engineer the model’s behavior.</li>
  <li>How to find induction head by checking the model’s attention pattern and doing logit attribution.</li>
</ol>]]></content><author><name></name></author><category term="AI" /><category term="ML" /><summary type="html"><![CDATA[I tried to replicating the Decoder-only transformer by following "Attention is all you need" paper and trained it on William Shakespeare's work.]]></summary></entry><entry><title type="html">Replicating Decoder-only Transformer by using William Shakespeare Corpus</title><link href="https://ziyuewang25.github.io/blog/2023/DLC-T1-Transformer/" rel="alternate" type="text/html" title="Replicating Decoder-only Transformer by using William Shakespeare Corpus" /><published>2023-06-19T00:00:00+00:00</published><updated>2023-06-19T00:00:00+00:00</updated><id>https://ziyuewang25.github.io/blog/2023/DLC-T1-Transformer</id><content type="html" xml:base="https://ziyuewang25.github.io/blog/2023/DLC-T1-Transformer/"><![CDATA[<p>I started following <a href="https://github.com/jacobhilton/deep_learning_curriculum/tree/master">Deep Learning Curriculum</a> written by <a href="https://www.jacobh.co.uk/">Jacob Hilton</a> and here is what I learnt from the exercise in <a href="https://github.com/jacobhilton/deep_learning_curriculum/blob/master/1-Transformers.md">Topic 1 - Transformer</a>. My solution is written in Colab <a href="https://colab.research.google.com/drive/18oP7mmz6sgC3pUembsOLdS6jSwlVbmIv?usp=sharing">T1-Transformers-solution.ipynb</a></p>

<p>It took me around 20 hours to finish the exercise and it totally worth it. Throughout the process I learnt:</p>
<ol>
  <li>How to implement the transformer model end-to-end.</li>
  <li>How to gather and clean the data for transformer model</li>
  <li>How to implement positional embedding, Attention, FNN, Residual Connection and put all of them together into transformer model.</li>
  <li>Switching between <code class="language-plaintext highlighter-rouge">LayerNorm(x + SubLayer(x))</code> and <code class="language-plaintext highlighter-rouge">x + SubLayer(LayerNorm(x)</code> doesn’t affect model performance.</li>
  <li>How to program in Pytorch more fluently and gathered a bunch of utility function for later usage.</li>
  <li>How to debug the model by using gradient flow and <code class="language-plaintext highlighter-rouge">torchviz.make_dot</code> to check model structure clearly.</li>
</ol>]]></content><author><name></name></author><category term="AI" /><category term="ML" /><summary type="html"><![CDATA[I tried to replicating the Decoder-only transformer by following "Attention is all you need" paper and trained it on William Shakespeare's work.]]></summary></entry><entry><title type="html">Replicating Diffusion Models on MNIST</title><link href="https://ziyuewang25.github.io/blog/2023/Diffusion-MNIST/" rel="alternate" type="text/html" title="Replicating Diffusion Models on MNIST" /><published>2023-06-11T00:00:00+00:00</published><updated>2023-06-11T00:00:00+00:00</updated><id>https://ziyuewang25.github.io/blog/2023/Diffusion-MNIST</id><content type="html" xml:base="https://ziyuewang25.github.io/blog/2023/Diffusion-MNIST/"><![CDATA[<p>My solution is written in colab <a href="https://colab.research.google.com/drive/1LcxLcVfxeFQWlEEWVTBx_LfNMaY3CoNg?usp=sharing">DiffusionModel-DeepLearningAI-Pytorch.ipynb</a></p>

<p>It took me around 8 hours to implement it and 2 hours are spent on gathering the proper data. Throughout the process I learnt:</p>

<ol>
  <li>The details of DDPM and DDIM algorithm and how diffusion model works</li>
  <li>Manipulating image data for diffusion modeling and demonstration purpose</li>
  <li>classifier-free guided diffusion to let the model generate, <code class="language-plaintext highlighter-rouge">even</code> or <code class="language-plaintext highlighter-rouge">divisible by 3</code> digits.</li>
</ol>]]></content><author><name></name></author><category term="AI" /><category term="ML" /><summary type="html"><![CDATA[I tried to replicating diffusion model (DDPM & DDIM) by following DeepLearningAI course and trained it on MNIST.]]></summary></entry><entry><title type="html">Metrics in Learn-To-Rank (LTR) problems</title><link href="https://ziyuewang25.github.io/blog/2023/Learn-To-Rank-Metrics/" rel="alternate" type="text/html" title="Metrics in Learn-To-Rank (LTR) problems" /><published>2023-04-09T00:00:00+00:00</published><updated>2023-04-09T00:00:00+00:00</updated><id>https://ziyuewang25.github.io/blog/2023/Learn-To-Rank-Metrics</id><content type="html" xml:base="https://ziyuewang25.github.io/blog/2023/Learn-To-Rank-Metrics/"><![CDATA[<p>Suppose we have <code class="language-plaintext highlighter-rouge">Q</code> queries, for each query <code class="language-plaintext highlighter-rouge">q</code>, it brings \(N_q\) results and normally we care about the top <code class="language-plaintext highlighter-rouge">K</code> docs retrieved.</p>

<p>All of the following metric is for 1 query, we need to average them to get an overall score for <code class="language-plaintext highlighter-rouge">Q</code> queries.</p>
<ol>
  <li><code class="language-plaintext highlighter-rouge">Accuracy@K</code>: Whether top K results contain the relevant results.
    <ol>
      <li>Formula: \(A(K)=(\sum_{i=1}^K I(i)) &gt; 0\). \(I(i)\) is an indicator function suggesting whether the \(i_{th}\) position is relevant or not.</li>
    </ol>
  </li>
  <li><code class="language-plaintext highlighter-rouge">Precision@K</code>: How many relevant results among the top K.
    <ol>
      <li>Formula: \(P(K) =\frac{1}{K}\sum_{i=1}^KI(i)\).</li>
      <li>Only for binary cases</li>
    </ol>
  </li>
  <li><code class="language-plaintext highlighter-rouge">Recall@K</code>: How many relevant results among the top K compared with all relevant results.
    <ol>
      <li>Formula: \(R(K) = \frac{1}{m}\sum_{i=1}^KI(i)\). \(m\) is the total number of relevant results overall.</li>
      <li>Only for binary cases</li>
    </ol>
  </li>
  <li><code class="language-plaintext highlighter-rouge">AP@K</code> (Average Precision): the weighted mean of precision at each threshold; the weight is the increase in recall from the prior threshold.
    <ol>
      <li>Formula: \(AP@K = \frac{1}{m}\sum_{k=1}^K P(k)I(k)\)</li>
      <li>A different way to represent \(AP@K\): We can also use <code class="language-plaintext highlighter-rouge">Recall@K</code> here by using its delta format \(\Delta R(k) = R(k) - R(k-1)\). It would be \(\frac{1}{m}\) if a relevant result is at position \(k\), otherwise it is 0. and it becomes \(AP@K = \sum_{k=1}^K P(k) * \Delta R(k)\). In other words, it is the area under Precision-Recall curve.</li>
      <li>Only for binary cases</li>
    </ol>
  </li>
  <li><code class="language-plaintext highlighter-rouge">RR</code> (Reciprocal Rank): reciprocal of the rank of the first relevant item in a ranked list.
    <ol>
      <li>Formula: \(RR = \frac{1}{\text{rank of the first relevant item}}\)</li>
      <li>Only for binary cases.</li>
    </ol>
  </li>
  <li><code class="language-plaintext highlighter-rouge">NDCG@K</code> (Normalized Discounted Cumulative Gain)
    <ol>
      <li><code class="language-plaintext highlighter-rouge">CG@K</code>: Sum of relevance of all results in a search result list \(CG@K = \sum_{k=1}^K rel(k)\), \(rel(k)\) is the relevance score of the result at \(k\).</li>
      <li><code class="language-plaintext highlighter-rouge">DCG@K</code>: Give earlier result higher weights: \(DCG@K = \sum_{k=1}^K\frac{2^{rel(k)} - 1}{ \log_2(k+1)}\)</li>
      <li><code class="language-plaintext highlighter-rouge">NDCG@K</code>: normalize <code class="language-plaintext highlighter-rouge">DCG</code> by its perfect ranking result (a.k.an Ideal <code class="language-plaintext highlighter-rouge">DCG</code> (<code class="language-plaintext highlighter-rouge">IDCG</code>)) to reduce the effect that different search results can vary in length.</li>
    </ol>
  </li>
  <li>Normalized Kendall tau distance at K:
    <ol>
      <li>\(K_n@K(\tau_1, \tau_2) = \frac{K_d}{\frac{1}{2}n(n-1)} = \frac{2}{n(n-1)} \sum_{\{i,j\}\in \mathbb{K}, i &lt; j} \bar K_{i,j}(\tau_1, \tau_2)\). \(\mathbb{K}\) is the set of unordered pairs of distinct elements among the top K in \(\tau_1\) and \(\tau_2\). \(\bar K_{i,j}(\tau_1, \tau_2) = 0\) if \(i\) and \(j\) are in the same order in \(\tau_1\) and \(\tau_2\), otherwise 1.</li>
    </ol>
  </li>
  <li>Spearman Rho:
    <ol>
      <li>Formula: \(\rho = \frac{cov(R(X), R(Y))}{\delta_{R(x)}\delta_{R(Y)}}\)</li>
    </ol>
  </li>
</ol>

<p>Reference:</p>
<ol>
  <li>https://en.wikipedia.org/wiki/Discounted_cumulative_gain</li>
  <li>https://en.wikipedia.org/wiki/Kendall_tau_distance</li>
  <li>https://towardsdatascience.com/normalized-discounted-cumulative-gain-37e6f75090e9</li>
</ol>]]></content><author><name></name></author><category term="AI" /><category term="ML" /><summary type="html"><![CDATA[Suppose we have Q queries, for each query q, it brings \(N_q\) results and normally we care about the top K docs retrieved.]]></summary></entry><entry><title type="html">KDS - Google Universal Image Embedding</title><link href="https://ziyuewang25.github.io/blog/2023/Kaggle-Digestion-Series-1/" rel="alternate" type="text/html" title="KDS - Google Universal Image Embedding" /><published>2023-03-01T00:00:00+00:00</published><updated>2023-03-01T00:00:00+00:00</updated><id>https://ziyuewang25.github.io/blog/2023/Kaggle-Digestion-Series-1</id><content type="html" xml:base="https://ziyuewang25.github.io/blog/2023/Kaggle-Digestion-Series-1/"><![CDATA[<ul>
  <li>Competition End time: 2022-10-17</li>
  <li>Submission Format: notebook &lt;= 9h</li>
</ul>

<h1 id="key-features">Key Features</h1>
<ol>
  <li>No training data provided.</li>
  <li>Ensemble cannot easily work. <a href="https://www.kaggle.com/competitions/google-universal-image-embedding/discussion/340546#1876558]">thread</a></li>
</ol>

<h1 id="evaluation"><a href="https://www.kaggle.com/competitions/google-universal-image-embedding/overview/evaluation">Evaluation</a></h1>
<p>mean Precision @ 5 metric + a small modification to avoid penalizing queries with fewer than 5 expected index images.</p>

\[mP@5 = \frac{1}{Q} \sum_{q=1}^Q \frac{1}{\min(n_q, 5)} \sum_{j=1}^{\min(n_q, 5)} rel_q(j)\]

<ul>
  <li>embedding dimension should be &lt;= 64</li>
  <li>compatible with TensorFlow 2.6.4 or Pytorch 1.11.0</li>
</ul>

<p>The host will use k-NN (k=5) to lookup for each test sample, using the Euclidean distance between test and index embeddings.</p>

<h1 id="data"><a href="https://www.kaggle.com/competitions/google-universal-image-embedding/data">Data</a></h1>
<p><strong>No training data provided.</strong>
Here is the distribution of test data.
<img src="https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F3258%2Fa02c90ad69a049b11a39bd38abcde2cb%2Fdomains.png?generation=1657141626387503&amp;alt=media" alt="" /></p>
<ol>
  <li>External data thread: https://www.kaggle.com/competitions/google-universal-image-embedding/discussion/337384</li>
</ol>

<h1 id="great-notebooks">Great Notebooks</h1>
<ol>
  <li><a href="https://www.kaggle.com/code/motono0223/guie-clip-tensorflow-train-example">CLIP-TF-Train-Example</a>
    <ol>
      <li>CLIP + Arcface + TPU training.</li>
    </ol>
  </li>
  <li><a href="https://www.kaggle.com/code/awsaf49/gcvit-global-context-vision-transformer">GCVIT</a>
    <ol>
      <li>Global Context Vision Transformer</li>
    </ol>
  </li>
  <li><a href="https://www.kaggle.com/code/evilpsycho42/understand-comp-domain-and-imagenet-21k-labels">Understand Comp Domain and ImageNet 21k Labels</a>
    <ol>
      <li>Understanding comp domain and labels</li>
    </ol>
  </li>
</ol>

<h1 id="solutions">Solutions</h1>

<ol>
  <li><a href="https://www.kaggle.com/competitions/google-universal-image-embedding/discussion/359316">1st place solution</a>
    <ol>
      <li>Using <a href="https://www.kaggle.com/competitions/google-universal-image-embedding/discussion/340043">pre-trained weights</a> w/o training or fine-tuning first.</li>
      <li>CLIP <a href="https://github.com/mlfoundations/open_clip">Github</a></li>
      <li><a href="https://arxiv.org/abs/1801.07698">ArcFace</a></li>
      <li>Add datasets to training list <strong>iteratively</strong> to save time and maintain good performance</li>
      <li>unfreeze the backbone after linear head is well trained, so we don’t need to worry about the random linear head would affect the backbone weights
        <ol>
          <li>use 10 times lower initial learning rate.</li>
          <li>Easy to get overfit and linear projection weights jumped sharply.</li>
          <li>So freeze linear head to train and add dropout to fully connection layer.</li>
        </ol>
      </li>
      <li>Clever ensemble to overcome different F(C, X) issues
        <ol>
          <li>resolution 224 + resolution 280</li>
        </ol>
      </li>
      <li>LAION-5B CLIP Model <a href="https://laion.ai/blog/large-openclip/">blog</a></li>
    </ol>
  </li>
  <li><a href="https://www.kaggle.com/competitions/google-universal-image-embedding/discussion/359525">2nd place solution</a>
    <ol>
      <li>dynamic margin</li>
      <li>stratified learning rate when training non-backbone part.</li>
    </ol>
  </li>
  <li><a href="https://www.kaggle.com/competitions/google-universal-image-embedding/discussion/359487">4th place solution</a></li>
  <li><a href="https://www.kaggle.com/competitions/google-universal-image-embedding/discussion/359161">5th place solution</a></li>
  <li>The rest <a href="https://www.kaggle.com/competitions/google-universal-image-embedding/discussion/359948">thread</a></li>
</ol>]]></content><author><name></name></author><category term="AI" /><category term="Kaggle" /><summary type="html"><![CDATA[Competition End time: 2022-10-17 Submission Format: notebook &lt;= 9h]]></summary></entry><entry><title type="html">Rock Climbing Knowledge - Injuries</title><link href="https://ziyuewang25.github.io/blog/2023/Climbing-Knowledge-Injuries/" rel="alternate" type="text/html" title="Rock Climbing Knowledge - Injuries" /><published>2023-02-25T00:00:00+00:00</published><updated>2023-02-25T00:00:00+00:00</updated><id>https://ziyuewang25.github.io/blog/2023/Climbing-Knowledge-Injuries</id><content type="html" xml:base="https://ziyuewang25.github.io/blog/2023/Climbing-Knowledge-Injuries/"><![CDATA[<p>From my own injury recovery experience, I gradually realize how important it is to warm up. There are many great resources online, so I decide to gather them down here for reference.</p>

<h1 id="pip-joint">PIP Joint</h1>
<ul>
  <li>https://www.camp4humanperformance.com/blog-2/pip-jugs
    <ul>
      <li><strong>high-rate rotational loading is more stressful on the fingers than static loading</strong></li>
      <li>when you can get your middle and distal bones around the edge of the jug, in that context, <strong>most of the stress in the fingers goes into the PIP joint.</strong></li>
      <li>The PIP Joint can suffer from overdoing easy climbing.</li>
      <li>A high volume of easy training can be <strong>counterproductive</strong>.</li>
      <li>PIP swelling are due to
        <ul>
          <li><strong>Collateral ligaments</strong> (sides of the joint)</li>
          <li><strong>A3 pulleys</strong> (hold the tendon close to the joint)</li>
          <li><strong>Volar plate</strong> (ligament across the joint where A3 attaches)</li>
        </ul>
      </li>
      <li><strong>dosage</strong> of stress stype is more important than intensity of the load.</li>
      <li>Treatment:
        <ul>
          <li><strong>Avoid the high-rate rotational loading</strong> for a few weeks to months.</li>
          <li>Don’t spend weeks to months climbing easy terrain. <strong>Especially in a gym.</strong></li>
          <li>Keep loading your fingers in an <strong>easily trackable way</strong> (ladder style). Fingerboard, campus board (feet on), spray wall etc.</li>
          <li>Be <strong>patient as hell</strong> in rehab! That’s the not easy part.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>https://www.camp4humanperformance.com/blog-2/pip-joint
    <ul>
      <li>PIP joint accounts for 85% of the motion for grip strength</li>
      <li>a hinge type joint which is stable only in the sagittal plane (flexing and extending)</li>
      <li><img src="https://images.squarespace-cdn.com/content/v1/59d03d018a02c7512bf8b05f/1491d85e-8d95-4c35-ae8e-56977850d9e7/%2311+pip+joint.png?format=750w" alt="" /></li>
      <li><strong>Three grades of collateral ligament injuries</strong></li>
      <li>General recommendations:
        <ul>
          <li><strong>Stiffness and joint contraction</strong> are common with injury.</li>
          <li>There is <strong>no consensus</strong> on best treatment strategies!</li>
          <li>Most injuries <strong>rarely return to full active range of motion.</strong></li>
          <li><strong>Treatment within 4 weeks</strong> is key.</li>
          <li>Immobilization beyond 3 weeks causes <strong>irreversible loss of motion!</strong></li>
          <li><strong>Early diagnosis</strong> and motion are suggested (specifically extensor power).</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>https://www.camp4humanperformance.com/blog-2/finger-pain
    <ul>
      <li><img src="https://images.squarespace-cdn.com/content/v1/59d03d018a02c7512bf8b05f/3e3090bf-516f-4521-a867-961b6c1873fb/%232+Finger+curl.png?format=750w" alt="" /></li>
      <li><strong>Doing something like finger-glides on a regular basis is not necessarily “healthy” for the joints of your fingers.</strong></li>
      <li>It really comes down to understanding the why behind any intervention. Everything comes with a cost.</li>
    </ul>
  </li>
</ul>

<h1 id="tfcc-injury">TFCC injury</h1>
<ul>
  <li>https://www.camp4humanperformance.com/blog-2/tfcc-injury
    <ul>
      <li><img src="https://images.squarespace-cdn.com/content/v1/59d03d018a02c7512bf8b05f/ae9fdd9a-8406-424d-a5a5-297d1da8fa78/%236+tfcc+injuries.png?format=750w" alt="" /></li>
      <li>Components:
        <ul>
          <li>A triangular shaped <strong>fibro-cartilaginous disc</strong> (shock absorbing, guiding motion)</li>
          <li>Ligaments between the <strong>ulna and radius</strong> on both sides (palmar &amp; dorsal)</li>
          <li>Ligaments between the <strong>ulna and the carpal bones</strong></li>
          <li>A <strong>meniscal type homologoue</strong> (shock absorbing)</li>
          <li>Sub-sheath of the <strong>ECU tendon</strong></li>
        </ul>
      </li>
      <li>Cause: repetitive axial loads to the wrist when the hand is in ulnar deviation and pronation.</li>
      <li>the <strong>dosage</strong> of the stress is the culprit</li>
      <li>Even though it is still recommended to do <strong>conservative management first</strong>, the statistics show that only 1/3 of patients get symptomatic relief. That number is highly dependent on the compliance but does show how tricky these injuries can be.</li>
    </ul>
  </li>
  <li><a href="https://www.memic.com/workplace-safety/safety-net-blog/2019/september/ouch-my-wrist-hurts">TFCC from work</a>
    <ul>
      <li><img src="https://www.memic.com/-/media/memic/images/workplace-safety/blog/2019/power-drills-to-keyboarding-figure-1-jpg/power-drills-to-keyboarding-figure-1-jpg.jpg?la=en&amp;hash=F3141D2EE74CDA2DCA20D9689F5990E33C7D8F4D" alt="" /></li>
    </ul>
  </li>
  <li><a href="https://www.youtube.com/watch?v=lTC3NKENAD8">https://www.youtube.com/watch?v=lTC3NKENAD8</a></li>
  <li>UIS Ulnar Impaction Syndrome
    <ul>
      <li><a href="https://carpaltunnelpros.com/2015/07/10/what-is-ulnar-impaction-syndrome/">What is Ulnar Impaction Syndrome? - Houston Wrist Pain Specialists: Elbow, Hand &amp; Finger Surgery</a></li>
    </ul>
  </li>
  <li>https://www.camp4humanperformance.com/blog-2/wrist-videos
    <ol>
      <li>5:3 x 3 repeater</li>
      <li>30s yielding isotonic</li>
      <li>5s overcoming isotonic</li>
      <li>5 rep isotonic</li>
      <li>velocity isotonic</li>
      <li>1-arm 90-degree PIMA with ulnar deviation</li>
      <li>1-arm 120-degree PIMA with ulnar deviation</li>
      <li>1-arm weighted hammer / band PIMA</li>
      <li>concentric focused ulnar deviation with hammer/band</li>
      <li>rapid concentric ulnar deviation with hammer/band
        <ul>
          <li>Building capacity in this part of the wrist is <strong>essential for staying injury free.</strong></li>
        </ul>
      </li>
    </ol>
  </li>
  <li>https://www.camp4humanperformance.com/blog-2/eccentrics-overprescribed
    <ul>
      <li><img src="https://images.squarespace-cdn.com/content/v1/59d03d018a02c7512bf8b05f/a32e5e47-c99c-4c35-b676-8ea0133e3e68/%238+eccentric+loads.png?format=750w" alt="" /></li>
      <li>Alternative
        <ul>
          <li><strong>Keeping the wrist neutral</strong> will do the same thing (mechanically), and it feels way less risky (good for pain reduction), especially if you’re an athlete with clicking in the wrist.</li>
          <li><strong>Wrist flexion isometric</strong> (shown on the left). Go heavy and hold for a longer time under tension.</li>
          <li><strong>Wrist extension isometric</strong> (opposite side of the forearm). Same idea.</li>
          <li><strong>Hammer curl isometric.</strong> Curl a heavy dumbbell to 90-degrees at the elbow (thumb up) and hold for time.</li>
          <li><strong>Tricep extension isometric.</strong> Opposite direction. Lower a heavy band or cable machine to 90-degrees (thumb up) and hold for time.</li>
        </ul>
      </li>
      <li>Eccentric flexion over a bench is not a very practical exercise.</li>
      <li>With pain at the wrist, <strong>keeping it neutral is a safe and reliable method.</strong></li>
      <li>This controlled load needs to <strong>change as your rehab progresses.</strong></li>
    </ul>
  </li>
</ul>

<h1 id="a2-pulley-injury">A2 Pulley Injury</h1>
<ul>
  <li>https://www.camp4humanperformance.com/blog-2/pulley-rupture</li>
  <li>https://www.camp4humanperformance.com/blog-2/pulley-injury</li>
</ul>

<h1 id="taping">Taping</h1>
<ul>
  <li>https://www.camp4humanperformance.com/blog-2/finger-taping
    <ul>
      <li>reducing stress to prevent an injury doesn’t make sense</li>
      <li><strong>taping should be part of progressive rehab plan,</strong> not a method to <em>prevent</em> one.</li>
      <li><img src="https://images.squarespace-cdn.com/content/v1/59d03d018a02c7512bf8b05f/a051125d-57f1-4061-a6fa-702a217606a2/%2329+finger+tape.jpg?format=1500w" alt="" /></li>
      <li>Pros
        <ul>
          <li>provide structural support and reduce pulley stress
            <ul>
              <li>H-tape is good for A2, A3 and A4. but <strong>not collateral ligament and volar plate injuries</strong></li>
            </ul>
          </li>
          <li>provide proprioception (awareness) in the joint</li>
          <li>Modify PIP joint range of motion: make it harder to do full-crimp</li>
          <li>Reduce pain: feels safe and reduces stress and anxiety.</li>
        </ul>
      </li>
      <li>Cons
        <ul>
          <li>not preventative. Listen to the body and back off the volume if it sore</li>
          <li>leads to further overuse.</li>
          <li>modifying ROM for too long can reduce it long-term</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h1 id="general-rehab">General Rehab</h1>
<ul>
  <li>https://www.camp4humanperformance.com/blog-2/random-rehab
    <ul>
      <li>consistency for rehab</li>
      <li>Standardizing warm up - Injury prevention program (IPP): <a href="https://static1.squarespace.com/static/59d03d018a02c7512bf8b05f/t/61f00ab0203e272d1b5f7aa0/1643121335193/Circuit+1.pdf">C1</a>, <a href="https://static1.squarespace.com/static/59d03d018a02c7512bf8b05f/t/61f00ef14ef0dd0b26f75909/1643122431683/Circuit+2.pdf">C2</a>, <a href="https://static1.squarespace.com/static/59d03d018a02c7512bf8b05f/t/61f00f6e8c861241421a2f87/1643122554700/Circuit+3.pdf">C3</a>, <a href="https://static1.squarespace.com/static/59d03d018a02c7512bf8b05f/t/61f00fada2b6c118a65a7ddc/1643122615792/Circuit+4.pdf">C4</a>, <a href="https://static1.squarespace.com/static/59d03d018a02c7512bf8b05f/t/61f0103f1e605f34fe47ea7e/1643122761385/Circuit+5.pdf">C5</a>, <a href="https://static1.squarespace.com/static/59d03d018a02c7512bf8b05f/t/61f0107a2ee7797ce0fd07b2/1643122816517/Circuit+6.pdf">C6</a>
        <ul>
          <li>a new outcome prediction</li>
        </ul>
      </li>
      <li>Rehab loading methods
        <ul>
          <li><img src="https://images.squarespace-cdn.com/content/v1/59d03d018a02c7512bf8b05f/6bdbccd0-378f-4747-903c-dc145d46fb48/%2317+rehab+loading.jpg?format=750w" alt="" /></li>
          <li>then: 30mm for A2, A3 pulleys.</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>https://www.camp4humanperformance.com/blog-2/finger-symptoms
    <ul>
      <li><strong>Absence of pain</strong> does not equal health.</li>
      <li><strong>Persistence of pain</strong> does not mean it’s not healing.</li>
      <li>Connective responds slowly, so <strong>you have to be patient.</strong> ASIDE FROM LOADING AND RECOVERING THERE IS NO METHOD TO MAKE THIS HAPPEN FASTER!</li>
      <li>Not loading at all (under loading) often times is more stressful for athletes. <strong>There are always things you can do!</strong></li>
      <li>Get help from a <strong>professional</strong>.</li>
    </ul>
  </li>
  <li>https://www.camp4humanperformance.com/blog-2/unique-finger
    <ul>
      <li><img src="https://images.squarespace-cdn.com/content/v1/59d03d018a02c7512bf8b05f/39d7cb97-8afd-468d-a2f4-24f46ac3eedb/%234.1.png?format=500w" alt="" /></li>
      <li><img src="https://images.squarespace-cdn.com/content/v1/59d03d018a02c7512bf8b05f/fda71a5a-ee5f-4d5d-bf3d-4d61778c4a09/%234.2.png?format=500w" alt="" /></li>
      <li>There are <strong>fewer rules with finger training</strong> than you likely think. Using a bigger edge to make your fingers stronger is totally acceptable.</li>
    </ul>
  </li>
</ul>]]></content><author><name></name></author><category term="Life" /><category term="Climbing" /><summary type="html"><![CDATA[Rock Climbing related injuries knowledge sharing.]]></summary></entry></feed>